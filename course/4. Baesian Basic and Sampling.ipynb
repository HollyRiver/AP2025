{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cf10d55e",
   "metadata": {},
   "source": [
    "# Baesian Basics and Sampling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7064c5e",
   "metadata": {},
   "source": [
    "## 1. Bayesian Intro."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7475c765",
   "metadata": {},
   "source": [
    "### Bayes Theorem."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "584325f5",
   "metadata": {},
   "source": [
    "$$P(Z|X) = \\frac{P(X|Z)P(Z)}{P(X)}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12906bd7",
   "metadata": {},
   "source": [
    "> conditional probability를 inverse-probability로 표현\n",
    "\n",
    "* $Z$: unknown random. 관측 불가능\n",
    "* $X$: $Z$에 의해서 결정되며, 관측 가능\n",
    "\n",
    "> 관측되지 않은 $Z$의 확률를 관측된 사건 $X$로 표현하는 것"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8457ca0",
   "metadata": {},
   "source": [
    "`-` $Z$에 확률을 줄 수 있다고 말함: philosophical issue로 판별\n",
    "\n",
    "* $Z$를 unknown quantity (as fixed)로 보면 상당히 다루기 어려우나, 랜덤으로 보면 쉬움\n",
    "* 확률 변수를 동원하여, 그 확률 변수로부터 규칙을 설명하는 것\n",
    "\n",
    "> DNN random initial -> random result. $\\to$ prediction이 고정되지 못함. 베이지안 관점에서 맞는 사실임"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f8efa64",
   "metadata": {},
   "source": [
    "`-` Inference / prediction\n",
    "\n",
    "* Inference: 기저의 분포를 식별. $\\to$ 샘플로부터 모집단에 대한 여러 정보 및 관계를 알아내는 것. 추정.\n",
    "* Prediction: 예측의 영역. $\\to$ 베이지안에서의 중요 개념. 확률적으로 prediction의 개념을 정교화\n",
    "\n",
    "> hypothesis: 기계학습에서는 모델의 의미로서 사용되는 경향이..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f95cd60",
   "metadata": {},
   "source": [
    "`Example`: 0/1의 특정 숫자가 주어졌을 때, 1이 나올 확률 (수식을 이해하는 것까지 바라진 않는다...?)\n",
    "\n",
    "$$R_i \\sim \\text{Bernoulli}(w), ~ i \\in [n], ~ w \\sim \\text{Beta}(1, 1)$$\n",
    "\n",
    "> $w$를 unknown parameter가 아닌 확률변수라고 가정 (Uniform Prior)\n",
    "\n",
    "$$p(r=1|R_1, R_2, ..., R_n)?$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20717caa",
   "metadata": {},
   "source": [
    "`Solution`\n",
    "\n",
    "* $w$를 알고 있다면, 그냥 확률은 $w$가 될 것... 관측값에 대하여 $w$는 어떻게 바뀌는가?\n",
    "\n",
    "> MLE에서 비율로 사용하는 것과 동일하지 않다.\n",
    ">\n",
    "> Prior가 바뀌면 확률이 바뀜"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c985958",
   "metadata": {},
   "source": [
    "$$\\frac{\\sum_i R_i + 1}{n + 2} ~~~~ \\frac{\\sum_i R_i}{n}$$\n",
    "\n",
    "> MLE와는 Prior 때문에 추정량이 다름\n",
    "\n",
    "\n",
    "* $\\hat p$: MLE, $\\hat p_B$: Baysian\n",
    "* 0.5를 중심으로 안쪽으로 모이도록 조정됨 $\\to$ $\\hat p$을 0.5쪽으로 조금 끌어당긴 것이 $\\hat p_B$이다.\n",
    "* 최종적으로는 Prior의 평균 방향으로 당겨진 것 (여기선 Uniform): Shirinkage Effect\n",
    "\n",
    "> Prior를 어떻게 설정하는지에 따라 Shirinkage 방향이 바뀜"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "322d26c3",
   "metadata": {},
   "source": [
    "`-` Interpretation\n",
    "\n",
    "* n과 $\\sum R_i$가 충분히 크다면, prior의 영향이 작아짐: data dominating\n",
    "> Sample size가 작을 수밖에 없을 때 prior effect가 커짐\n",
    "* 보통은 prior를 어떻게 주어도 MLE보다 약간 값이 작게 나오는 경향이 많음 $\\to$ 성능이 더 좋아지는 경우가 있음\n",
    "> 아무리 값이 작아도, 그 값이 매우 다수인 경우 그 영향력이 클 수 있다. $\\to$ shirinkage를 도입하여 큰 값은 덜 줄이고 작은 값은 많이 줄임. sample mean 쓰는 것 보다 prior를 잘 사용함으로써 여러가지 상황에서의 문제를 줄일 수 있음"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fb2db20",
   "metadata": {},
   "source": [
    "`-` 정리\n",
    "\n",
    "* 모수를 변화시키면서 예측을 수행시킬 수 있으며, 이는 일반적으로 평균과 다르다. (대수의 법칙에 따라 평균과 유사)\n",
    "* 평균보다 절대값이 작아지는 것이 도움이 된다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dc69d64",
   "metadata": {},
   "source": [
    "## 2. Prior, Model, and Posterior"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "268d2e72",
   "metadata": {},
   "source": [
    "### Notations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89e7f6c0",
   "metadata": {},
   "source": [
    "* $p(\\theta)$: random parameter에 대한 확률 (pdf) $\\to$ law or **prior** p\n",
    "* $p(y | \\theta)$: data distribution given $\\theta$\n",
    "* $L(\\theta) = p(y | \\theta)$: $y$를 fixed scalar로 취급할 때, $\\theta$의 값을 변화시킴에 따라 변화하는 Likelihood. pdf가 아님($\\theta$ 관점).\n",
    "* $p(\\theta | y)$: posterior distribution given $y$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc3cf0b8",
   "metadata": {},
   "source": [
    "`-` Posterior and usage of its components.\n",
    "\n",
    "$$p(\\theta | y) = \\frac{p(y|\\theta)p(\\theta)}{p(y)} := \\frac{L(\\theta|y) p(\\theta)}{p(y)} \\propto L(\\theta | y)p(\\theta)$$\n",
    "\n",
    "* $p(y)$는 상수 같은 거니까 그대로 둬도 됨\n",
    "* $\\theta$가 argument라는 점을 명시해주기 위해서 Likelihood로 정의를 바꿈\n",
    "* 커널만 알면, 상수로 취급되는 부분은 전부 유도해낼 수 있음 $\\to$ 어차피 적분값으로 나누면, 확률밀도함수의 기본 성질을 만족하게 됨"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e04dce81",
   "metadata": {},
   "source": [
    "`-` Prior\n",
    "\n",
    "* Distribution for parameter (when no observation) $\\to$ 정보를 입력. (평균, 분산, shape, ... 등등의 subject)\n",
    "* Construction\n",
    "> 1. 해당 도메인의 전문가들이 모여 분포를 파악 elicitation\n",
    "> 2. 평균, 분산만 대충 파악하고 가우시안/베타 분포...\n",
    "> 3. **non-informative**: prior가 gaussian이면 mean에 몰리므로 데이터가 들어와도 $L(\\theta|y)$가 왜곡될 수 있음. uniform이여도 구간이 정해져 있어서 곤란... 그냥 $p(w) = c, -\\infty < w < \\infty$를 사용. $\\to$ posterior를 들여왔을 때 적분해서 1이 되기만 하면 충분하다...\n",
    ">\n",
    ">   Example: $p(\\mu) ∝ 1, p(\\sigma) ∝ \\frac{1}{\\sigma} \\to$ scale이 바뀌어도 형태가 계속해서 유지됨... 적분해도 1이 안나옴\n",
    "\n",
    "* 샘플이 커지면 prior effect가 작아짐 ㅇㅇ\n",
    "* Complex가 높은 모델(DNN: Weight + Bias에 모두 Prior를 줘야 함)의 경우, 샘플이 Prior Effect를 압도할 수 없게 됨\n",
    "> 이때문에 베이지안에서 딥러닝을 사용하기 어려움... non-informative도 적분이 안되는 경우도 있음..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26735992",
   "metadata": {},
   "source": [
    "`-` Model or Likelihood\n",
    "\n",
    "* 데이터는 posterior에 Likelihood로 영향을 줄 수 있음\n",
    "* 데이터의 크기가 커질수록 Posterior에 데이터가 주는 영향력이 커짐 ㅇㅇ\n",
    "\n",
    "`-` Posterior\n",
    "\n",
    "* random parameter의 posterior $\\to$ 분포를 추정하는 문제\n",
    "* Posterior는 분포임 (point estimator가 아님. 분포를 만들어버린 다음에 점과 구간을 뽑아내는 것. 훨씬 informative한 객체)\n",
    "> 분포를 근사할 때, pdf의 커널 정도로 샘플링하는 테크닉. 샘플로 population의 estimate를 계산"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5db11e15",
   "metadata": {},
   "source": [
    "`-` Properties of posterior\n",
    "\n",
    "$y_1, y_2$가 관측되었을 때, $\\theta$의 posterior를 계산\n",
    "\n",
    "1. $p(\\theta | y_1, y_2) \\propto L(\\theta | y_1, y_2) p(\\theta) \\to p(y_2 | \\theta, y_1) p(\\theta | y_1)$\n",
    "\n",
    "> $p(\\theta) \\to p(\\theta | y_1) \\to p(\\theta | y_1, y_2) \\to \\cdots$의 방식으로 순차적인 업데이트가 가능\n",
    ">\n",
    "> posterior를 prior처럼 사용하는 방식으로, 온라인 러닝에서 유용하게 사용됨\n",
    "\n",
    "2. $p(\\theta | y) = k(\\theta)h(y) \\to h(y) = 1/ \\int k(\\theta)\\theta$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a9f9ec2",
   "metadata": {},
   "source": [
    "### Example"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fb365e7",
   "metadata": {},
   "source": [
    "`-` Beta-binomial\n",
    "\n",
    "$$\\begin{align}\n",
    "y|\\theta & \\sim \\text{Binom}(n, \\theta) \\\\\n",
    "p(\\theta) & ≡ \\text{Beta}(\\theta, \\alpha, \\beta) = \\frac{\\Gamma(\\alpha) \\Gamma(\\beta)}{\\Gamma (\\alpha + \\beta)} \\theta^{\\alpha - 1}(1-\\theta)^{\\beta - 1} \\\\\n",
    "E[\\theta] & = \\frac{\\alpha}{\\alpha + \\beta}, ~ \\text{Var}(\\theta) = \\frac{\\alpha \\beta}{(\\alpha + \\beta)^2 (\\alpha + \\beta + 1)}\n",
    "\\end{align}$$\n",
    "\n",
    "> prior를 Beta분포로 함"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28ddc39c",
   "metadata": {},
   "source": [
    "* Joint distribution of $p(y, \\theta) = p(y | \\theta)p(\\theta)$.\n",
    "\n",
    "> 베타 분포를 먹인 순간부터, 항이 정리됨\n",
    ">\n",
    "> 상수가 바뀌는 것은 나중에 처리하면 되고, $\\theta$에 대한 항만 정리하면...\n",
    "\n",
    "$$\\theta^{\\alpha + y - 1}(1 - \\theta)^{n-y +\\beta-1}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8c394c3",
   "metadata": {},
   "source": [
    "* Posterior of $\\theta$ given $y$\n",
    "\n",
    "$$p(\\theta | y) \\propto \\theta^{\\alpha + y - 1}(1 - \\theta)^{n-y +\\beta-1} ≡ \\text{Beta}(\\theta | y + \\alpha, n - y + \\beta)$$\n",
    "\n",
    "> $E[\\theta | y] = \\frac{y + \\alpha}{n + \\alpha + \\beta} = \\frac{y}{n} \\times \\frac{n}{n + \\alpha + \\beta} + \\frac{\\alpha}{\\alpha + \\beta} \\times \\frac{\\alpha + \\beta}{n + \\alpha + \\beta} \\to$ $n$이 커질수록 prior effect가 줄어들고, data가 dominant해짐. posterior의 mean은 sample mean과 prior의 mean으로 이뤄짐\n",
    ">\n",
    "> $Var(\\theta | y) = O(\\frac{1}{n}) \\to$ 샘플이 커질수록 posterior의 분산이 작아짐. 즉, 분포가 한 점에 수렴. 보통 작아짐 ㅇㅇ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c6fc137",
   "metadata": {},
   "source": [
    "`-` Normal-normal in mean\n",
    "\n",
    "$$\\begin{align}\n",
    "y | \\theta & \\sim N(\\theta, \\sigma^2) \\\\\n",
    "\\theta & \\sim N(0, \\kappa \\sigma^2)\n",
    "\\end{align}$$\n",
    "\n",
    "> 단, $\\sigma^2$는 known scalar"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9b051ec",
   "metadata": {},
   "source": [
    "* Joint distribution of $p(y, \\theta) = p(y | \\theta)p(\\theta)$\n",
    "\n",
    "> 어떻게든 $h(\\theta)$와 그 바깥의 것으로 나눔 (지수족 느낌으로다가)\n",
    ">\n",
    "> 정규 분포의 포맷으로 어떻게든 바꿈 ㅇㅇ\n",
    "\n",
    "$$p(\\theta | y) \\propto N(\\theta | y(1 + 1/\\kappa)^{-1}, (1 + 1/\\kappa)^{-1}\\sigma^2)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16d909dd",
   "metadata": {},
   "source": [
    "* Properties\n",
    "\n",
    "1. mean은 아래와 같이 표현될 수 있음\n",
    "\n",
    "$$y \\times \\frac{1}{1 + 1/\\kappa} + 0 \\times \\frac{1/\\kappa}{1 + 1/\\kappa}$$\n",
    "\n",
    "> Sample에서 계산한 $y$와, prior에서의 mean이 합쳐져 있음\n",
    "\n",
    "\n",
    "2. 각 통계량\n",
    "\n",
    "$$\\begin{align}\n",
    "E[\\theta | y] & = \\bar{y} \\times \\frac{n}{n + 1/\\kappa} + \\mu_0 \\times \\frac{1/\\kappa}{n + 1/\\kappa} \\\\\n",
    "\\text{Var}(\\theta | y) & = \\frac{\\sigma^2}{n + 1/\\kappa}\n",
    "\\end{align}$$\n",
    "\n",
    "> 분산을 줄이는 효과가 있음: Prior가 Overfitting을 막을 수 있음\n",
    ">\n",
    "> 평균 추정에서 bias가 존재하게 됨. 데이터가 커질 수록 상쇄됨\n",
    "\n",
    "3. $1/\\kappa$는 sample size of the prior라고 함. 보통 상수로 택하여, 데이터를 보기 전에 결정함.\n",
    "\n",
    "4. marginal, joint, conditional 전부 normal임"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40a8f340",
   "metadata": {},
   "source": [
    "`-` Normal-normal in mean and variance\n",
    "\n",
    "* Prior를 독립으로 하지 않고, 조건부로 처리\n",
    "\n",
    "$$y | \\theta, \\sigma^2 \\sim N(\\theta, \\sigma^2), ~~ \\theta | \\sigma^2 \\sim N(0, \\kappa \\sigma^2)$$\n",
    "\n",
    "* $p(1/\\sigma^2) \\propto (1/\\sigma^2)^{-1}$ (improper prior)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d17c65bd",
   "metadata": {},
   "source": [
    "* Joint distribution of $p(y, \\theta, 1/\\sigma^2)$\n",
    "\n",
    "$$(2\\pi \\sigma^2)^{-\\frac12} \\exp (-0.5(y - \\theta)^2/\\sigma^2)(\\kappa\\sigma^2)^{-\\frac12} \\exp(-0.5 \\theta^2 / (\\kappa \\sigma^2))(1/\\sigma^2)^{-\\frac12}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "910b1b2b",
   "metadata": {},
   "source": [
    "* Posterior of $\\theta$ given $y$.\n",
    "\n",
    "$$p(\\theta | 1/\\sigma^2, y) \\propto N(\\theta, y(1 + 1/\\kappa)^{-1}, (1+1/\\kappa)^{-1}\\sigma^2)$$\n",
    "\n",
    "$$p(1/\\sigma^2 | y) \\propto (1/\\sigma^2)^{\\frac12 - 1}$$\n",
    "\n",
    "> 감마 분포를 따름 (카이제곱 분포로 유도되며, 최종적으로 posterior of $\\theta$ $p(\\theta | y)$는 t분포가 나옴)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93a10f2a",
   "metadata": {},
   "source": [
    "### 정?리"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

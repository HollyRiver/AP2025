{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a381f223",
   "metadata": {},
   "source": [
    "## 1. AI에 대한 개괄적 설명"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41668ec1",
   "metadata": {},
   "source": [
    "### **A. 인공지능**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "600ab4b6",
   "metadata": {},
   "source": [
    "명확하게 정리된 유일한 정의는 없음\n",
    "\n",
    "`-` **AI에 대한 기술적 정의 (Technical definition)**:\n",
    "* 인간의 오감과 관련된 정보를 통합하여 분석, 학습, 예측\n",
    "* 의사결정 수행\n",
    "* 새로운 정보 학습 시 이전에 배운 정보를 유지하여 학습 가능: Continual Learning $\\to$ 새로운 태스크 데이터 학습 시 기존의 특정 태스크 정보가 점점 잊혀지는데, 이를 해결\n",
    "* 언어 처리와 메타 러닝 등을 수행할 수 있음"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74a73407",
   "metadata": {},
   "source": [
    "`-` 뇌과학 관점에서의 인공지능\n",
    "\n",
    "* Neural Network\n",
    "* 인간의 뇌를 모방"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f434d988",
   "metadata": {},
   "source": [
    "`-` 공학적 관점에서의 인공지능\n",
    "\n",
    "* XOR 문제의 해결을 위한 Multi-Layer-Perceptron\n",
    "* 통계학에서의 비선형 모델링 $y = f(x) + \\epsilon$ -> $f$의 설계\n",
    "* MLP $f = g_2 \\circ g_1$ : 미분 어려움, 해석에서 문제 있음\n",
    "> Complexity 훨씬 높음, 다양한 문제에 적용 가능 $\\to$ DNN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a1a16d5",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "`-` Application Example\n",
    "\n",
    "* Precision Medicine: 의료의 개인화 Personalization\n",
    "* Virtual Assistant: 가상 비서\n",
    "* Expert System\n",
    "* Auto Driving"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4049e277",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "* 추론 Reasoning\n",
    "* 자율적인 의사결정 및 작업 수행 Agent\n",
    "* Physical AI\n",
    "* Computer Vision/Speech/Expert System은 이미 인간을 능가하였음\n",
    "* Continuous learning/Meta learning/Reinforcement learning에서 상당한 발전"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b423a56",
   "metadata": {},
   "source": [
    "### **B. DNN**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91534ac8",
   "metadata": {},
   "source": [
    "`-` Simple DNN (Multi-Layer Perceptron; MLP)\n",
    "\n",
    "$$f({\\boldsymbol x}) = a(g_L \\circ g_{L-1} \\circ \\cdots \\circ g_1 ({\\boldsymbol x}))$$\n",
    "\n",
    "* $g_l(\\boldsymbol x) = \\sigma ({\\boldsymbol W_l \\boldsymbol x +  \\boldsymbol b_l})$이며, 해당 함수 $f$는 레이블 예측에 활용됨. 파라미터를 통해 학습되는 함수.\n",
    "* $\\sigma$는 활성화 함수(activation function)이며, $a(\\cdot) = {\\boldsymbol W_a ~ \\cdot} + {\\boldsymbol b_a}$는 스칼라 함수 또는 벡터 함수임(netout 벡터를 반환)\n",
    "\n",
    "$$\\begin{bmatrix} h_1 \\\\ h_2 \\end{bmatrix} = \\begin{bmatrix} w_{11} & w_{12} \\\\ w_{21} & w_{22} \\end{bmatrix} \\begin{bmatrix} x_1 \\\\ x_2 \\end{bmatrix}$$\n",
    "\n",
    "> 단순 레이어 변환. 선형 변환임: $\\boldsymbol W_l  \\boldsymbol x$의 형태\n",
    "\n",
    "$$\\begin{bmatrix} h_1 \\\\ h_2 \\end{bmatrix} = \\begin{bmatrix} w_{11} & w_{12} \\\\ w_{21} & w_{22} \\end{bmatrix} \\begin{bmatrix} x_1 \\\\ x_2 \\end{bmatrix} \\overset{\\sigma}{\\to} \\begin{bmatrix} \\sigma (h_1) \\\\ \\sigma (h_2) \\end{bmatrix}$$\n",
    "\n",
    "> 해당 선형 변환에 ReLU, sigmoid 등의 비선형 변환(activation function)을 추가하여 복잡한 형태를 만들어냄. $W$의 차원은 자유롭게 설정 가능"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b8ea660",
   "metadata": {},
   "source": [
    "`-` 인간의 뉴런과 DNN의 차이\n",
    "\n",
    "* **Activation** : 전기 신호 $\\approx$ 활성화 함수\n",
    "> 인간의 뇌의 시냅스 연결 - 무작위적, 비정형\n",
    ">\n",
    "> DNN의 퍼셉트론 간 연결 - 선형적?, 정형\n",
    "\n",
    "* **역전파 backpropagation**\n",
    "> 인간의 뇌 - 전체를 바꾸지 않고 일부만 변경하는 것이 가능\n",
    ">\n",
    "> DNN - 개별 weight만 바꿀 수 없음. 모든 뉴런을 다 변경해야 함 $\\to$ 비효율적, complexity 제약"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8045076f",
   "metadata": {},
   "source": [
    "`-` **Loss function**\n",
    "\n",
    "$$l(y, f({\\boldsymbol x}))$$\n",
    "\n",
    "* $l$은 일반적으로 convex function을 가정: CrossEntropy, MSE\n",
    "* $f(x)$가 정해져 있다면 loss function 자체만으로는 convex 하지만, $f$의 형태가 $\\theta$에 의해 바뀌기 때문에 loss function은 convex하지 않아 최적화가 어려움\n",
    "* 신경망의 앞부분은 Feature Extractor의 역할, 뒷부분은 손실 측정의 역할\n",
    "* $\\theta$의 비중이 압도적으로 큼. 즉, Feature extractor가 중요한 정보를 가지고 있음."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f37bf685",
   "metadata": {},
   "source": [
    "`-` 다양한 활용\n",
    "\n",
    "* **CNN**: `Convolution Kernel`을 도입하여 엣지 탐색, characterize로 이미지를 신경망이 더 잘 이해할 수 있도록 도움\n",
    "* **Shallow NN**: hidden layer가 두 개 이하인 경우 사용하기도 하는 표현\n",
    "* **Gradient vanishing**: Activation funciton 중 `sigmoid`,`tanh`는 각각 최대 편미분 값이 0.25, 1이기 때문에 레이어가 깊어질 수록 편미분 값들이 반복적으로 곱해지면서 1보다 작아지게 되고 기울기가 소실되도록 한다. 따라서 `ReLU`, `leaky ReLU`와 같이 적당한 범위 내에 값을 가질 수 있도록 하는 활성화 함수를 선호한다.\n",
    "* **Batch normalization**: 배치 단위로 입력을 정규화. 파라미터 스케일에 대한 민감도를 낮추는 역할\n",
    "* **Dropout**: 인간의 뇌가 랜덤하게 connection된다는 점을 모방하여 학습을 부드럽게 만듦\n",
    "* **Skip connection**: 레이어 연결 과정에서 몇 개의 층을 스킵하여 그래디언트 계산이 쉽도록 만듦\n",
    "* **Regularization**: 손실함수에 패널티를 추가하여 파라미터 크기를 너무 크지 않도록 억제"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08c86cb5",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "`-` **Stochastic Gradient Descent** : 랜덤 배치를 사용하는 경사 하강법\n",
    "\n",
    "* 전체 데이터 대신 무작위로 선택한 mini-batch를 사용하여 그래디언트를 계산, 작은 learning rate로 업데이트하는 과정을 반복\n",
    "* 일부의 데이터만 손실함수 계산에 사용함으로써 손실함수 개형을 바꿈\n",
    "* loss를 감소시키기는 어려우나, 특정 구간을 넘어가면 loss function의 flat 구간에 도착할 것으로 생각하고 최적화\n",
    "* 미니배치를 사용함에 따라 그래디언트에 노이즈를 발생시켜 bad local minimum에서 탈출시킬 수 있도록 도울 수 있음\n",
    "\n",
    "$$W_t \\leftarrow W_{t-1} - η \\nabla l_{W_{t-1}}(\\mathcal{B})$$\n",
    "\n",
    "* 이론적으로 learning_rate는 step $t$마다 일정한 규칙에 의해 줄어드는 것이 이상적임 $\\sum_t η_t = \\infty, ~ \\sum_t η_t^2 < \\infty \\to \\text{e.g.,} ~~ η_t = \\frac1t$\n",
    "* 실제로는 다양한 스케줄러가 사용되며, learning rate를 크게 만든 뒤 작게 조정하는 Cyclical learning rate는 NLP에서 사용하는 것이 좋다고 알려져 있음"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e3a4892",
   "metadata": {},
   "source": [
    "`-` **Data Loader**\n",
    "\n",
    "* 데이터의 용량이 매우 커서 GPU의 VRAM에 모두 올릴 수 없는 경우, 대용량의 데이터를 배치 단위로 나누어 순차적으로 GPU에 올려 학습\n",
    "* 배치를 사용하더라도 LLM 학습에서는 입력 시퀀스의 길이를 증가시켜 최대 출력 토큰 길이를 향상시키기 위해 VRAM이 더 많이 필요하게 됨\n",
    "* Data Loader는 CPU에서 미리 데이터를 준비한 뒤, GPU로 빠르게 전달하는 병렬 처리를 수행하여 효율적으로 배치를 관리"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11a3f584",
   "metadata": {},
   "source": [
    "## 2. Transfer Learning (단순 전이 학습)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a6d7bcf",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "### **A. Basic**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a1ceef8",
   "metadata": {},
   "source": [
    "`-` pre-trained model and target task\n",
    "\n",
    "* pre-trained model이 주어졌을 때, 입력 데이터의 변환된 표현을 획득 가능\n",
    "* 해당 표현은 새로운 문제에서 source와 target이 공통 요소를 가질 때 유용\n",
    "> DNN에서 feature extractor 역할을 하는 부분은 다른 곳에 활용해도 잘 작동하지 않을까란 아이디어\n",
    ">\n",
    "> General한 pre-trained model을 다른 도메인에 적용"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faf045a6",
   "metadata": {},
   "source": [
    "`-` Mathmetical Framework\n",
    "\n",
    "$T, S$가 Target, Source domain이라고 할 때,\n",
    "\n",
    "1. $g_i: X_s \\to Y_s$ hypothesis of source tasks. (함수의 형태가 이런 꼴일 것이라는 가설을 세우는 느낌으로 이해)\n",
    "2. $f: X_t \\to Y_t$ hypothesis of target task. 배우고 싶은 요소\n",
    "\n",
    "* common $c$, specific parts $w_i, v$로 hypothesis를 분해\n",
    "\n",
    "$$g_i = w_i \\circ c, ~ f = v \\circ c$$\n",
    "\n",
    "> $c$는 소스 데이터에서 학습 가능, $v$는 타겟 데이터로 학습 가능 $\\to$ $v$만 배우면 됨\n",
    ">\n",
    "> 대용량의 데이터셋으로 훈련된 모델 $g_i$와, $f$가 공유하는 특징이 클 수록 전이학습이 효과적이다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48551562",
   "metadata": {},
   "source": [
    "`-` Scratch, Freezing, Fine-Tuning\n",
    "\n",
    "* 소스 모델의 마지막 output layer를 제거하고, target task를 위한 additional layers를 부착하여 end-to-end 구조로 구성됨\n",
    "* Scratch: 전체 가중치를 랜덤 초기값으로 설정하고, target 데이터로 전체 모델을 학습. 전체 모델을 재훈련함으로써 데이터가 적은 경우 모형이 제대로 학습되지 못함\n",
    "* Freezing: 소스 모델의 가중치는 동결한 채, additional layers만 훈련\n",
    "* Fine-Tuning: 소스 모델의 가중치를 초기값으로 설정하고, target 데이터로 전체 모델을 학습\n",
    "* Hybrid: Feature Extractor(소스 모델)의 일부 레이어를 동결시키고, 일부 레이어만 기존 가중치를 초기값으로 하여 additional layers와 같이 훈련. 어떤 지점에서 구간을 잘라야 할 지 결정하는 문제가 있으므로, 일반적으로 활용되지는 않음"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76bdcf06",
   "metadata": {},
   "source": [
    "### **B. Mathmatical Frameworks**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49f98346",
   "metadata": {},
   "source": [
    "`-` Risk of Transfer Learning\n",
    "\n",
    "$C(\\mathcal{C}), C(\\mathcal{V})$를 $\\mathcal{C}, \\mathcal{V}$의 복잡도 측정값이라 하고, $t, n$을 각각 소스 태스크의 수와 개별 소스 태스크에서의 샘플 사이즈로, $m$을 타겟 태스크의 샘플 사이즈라고 할 때\n",
    "\n",
    "$$\\tilde{O} \\left( \\frac{1}{\\nu} \\sqrt{\\frac{C(\\mathcal{C}) + t C(\\mathcal{V})}{nt}} + \\sqrt{\\frac{C(\\mathcal{V})}{m}} \\right)$$\n",
    "\n",
    "* 현재 target sample size인 $m$을 키우기 어려운 상황이므로, 완전히 다른 태스크인 $\\mathcal{V}$의 비중이 줄어들어야 한다. 즉, 소스와 타겟의 공통 태스크 비중이 커야 복잡도가 줄어든다.\n",
    "* 또한 소스 모델이 큰 모델일 수록 $nt$의 값이 커져 복잡도가 감소한다.\n",
    "* 즉, 좋은 소스 모델을 찾아서 타겟 문제를 해결하면 된다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8652c6b",
   "metadata": {},
   "source": [
    "`-` Transfer Learning과 관련된 문제\n",
    "\n",
    "* Meta Learning: 학습을 위한 학습. 여러 언어들을 배운 모델이 다른 언어를 쉽게 학습할 수 있을까?\n",
    "* Adaptive Learning: 배운 지식을 공통점이 조금 있는 다른 분야에서 활용할 수 있을까?\n",
    "* OOD: 학습 데이터의 분포와 평가 데이터의 분포가 다른 상황에서 모델이 정상 작동할 수 있을까? 현실에서의 문제 해결에 매우 중요."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37786e0e",
   "metadata": {},
   "source": [
    "## 3. Transfer Learning (2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "673e57aa",
   "metadata": {},
   "source": [
    "### **A. Domain Adaptation**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fd0d2e4",
   "metadata": {},
   "source": [
    "`-` Definition\n",
    "\n",
    "* 소스 도메인의 데이터로 훈련된 모델을 관련된 다른 타겟 도메인에서 잘 작동하도록 만드는 기술\n",
    "\n",
    "> Superviesd to Supervised\n",
    ">\n",
    "> 적은 라벨의 지도학습을 많은 라벨의 지도학습으로\n",
    ">\n",
    "> Unsupervised to Unsupervised: PCA 변환 행렬을 다른 데이터에 그대로 사용할 수 있는가?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7461c3a5",
   "metadata": {},
   "source": [
    "`-` Examples\n",
    "\n",
    "* 특정 지역의 저해상도의 이미지와 레이블 + 레이블링 되지 않은 고해상도 이미지\n",
    "* 다수의 레이블로 처리된 시뮬레이션 이미지 + 더 적은 레이블의 현재 이미지"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3abb5a2",
   "metadata": {},
   "source": [
    "`-` Mathematical formulation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bda4239d",
   "metadata": {},
   "source": [
    "$$\\begin{align} & p_t(x) \\neq p_s(x) \\\\\n",
    "& p_t(T(x)) = p_s(T(x)) \\\\\n",
    "& p_t(y | T(x)) = p_s(y | T(x))\n",
    "\\end{align}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c8267b2",
   "metadata": {},
   "source": [
    "$p_t,~ p_s$가 타겟/소스 도메인의 분포이고, $T$를 변환이라고 할 때."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ce7983c",
   "metadata": {},
   "source": [
    "* 타겟과 소스의 분포를 일치시키는 변환 $T$를 찾는다.\n",
    "\n",
    "* 서로 다른 분포의 소스/타겟 도메인이 존재할 때, $T$라는 변환은 각 소스의 데이터 x에 대하여 $T(x)$가 두 도메인에 대해 같은 분포를 가지도록 만든다.\n",
    "* 해당 변환을 찾을 수 있다면, 각 도메인에서 T(x)가 주어졌을 때 y에 대한 조건부 확률도 동일해야 한다. -> 변환하여 분류할 수 있는 형태로 주어진다.\n",
    "\n",
    "> 현실에선 마지막은 이상적인 경우임. $T$를 찾기도 어려움. $T$를 찾고, 마지막 조건에 근접하도록 regularization."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d77a00da",
   "metadata": {},
   "source": [
    "### 왜 분포를 같게 만들려 하는가?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7974d569",
   "metadata": {},
   "source": [
    "* X가 주어졌을 때 y의 확률이 어떻게 되는지를 알아야 지도학습 수행 가능\n",
    "* 두 데이터가 완전히 일치하지 않더라도, 하나의 확률 분포를 가지고 있다면 $\\to$ 동일한 예측을 수행할 수 있음\n",
    "* 동일한 데이터: feature value가 똑같다는 게 아니라, 분포가 동일하다는 의미로써 언급"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ffd45bf",
   "metadata": {},
   "source": [
    "`-` 변환 후 분포의 동일성을 어떻게 파악할 것인가?\n",
    "\n",
    "* 둘 다 정규분포를 따른다고 가정한 뒤, 평균과 분산을 맞춤: 정규분포가 아닌 데이터에 일반화 불가능\n",
    "* KL-divergence, MMD 등을 사용함"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "907c8eb7",
   "metadata": {},
   "source": [
    "### Metric Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf70eebb",
   "metadata": {},
   "source": [
    "1. 두 점 사이의 거리를 고려 $x_s^i,~ x_t^i$\n",
    "\n",
    "$$d_W (x_s^i, x_t^i) = (x_s^i - x_t^i)^{\\top} W (x_s^i - x_t^i)$$\n",
    "\n",
    "> 유클리디안 거리의 제곱 수식에 $W$를 넣음.\n",
    "\n",
    "2. $W$는 $W^{\\frac12}$로 나타낼 수 있으므로, 위 수식은 $W^{\\frac12}x_s^i$와 $W^{\\frac12}x_t^i$간 거리. 각 점을 변환한 상태에서의 변환이라고 말할 수 있음. (선형 변환)\n",
    "\n",
    "3. 선형으로 가는 조건에서, $x_s^i,~ x_t^i$의 레이블이 같다면: 변환 후 거리가 짧아야 함\n",
    "    \n",
    "    레이블이 다르다면: 변환 후 거리가 멀어야 함 -> 3번 조건을 최대한 만족시키는 방향"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fb8cd14",
   "metadata": {},
   "source": [
    "`1.` Semi-supervised domain adaptation\n",
    "\n",
    "> 레이블이 같으면 거리가 $u$(upper)를 넘기지 않고, 레이블이 다르면 거리가 $l$(lower)보다 긴 변환이여야 함.\n",
    ">\n",
    "> 어떤 값을 정하는지는 자유...\n",
    "\n",
    "`2.` positive-metrix $W$\n",
    "\n",
    "arg min Tr(W) - log det(W)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c9f5616",
   "metadata": {},
   "source": [
    "### Asymmetric Transformations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d437310b",
   "metadata": {},
   "source": [
    "1. Using similarity: inner product-based\n",
    "\n",
    "$$\\text{sim}_W (x_s^i, x_t^i) = {x_s^i}^{\\top} W x_t^i$$\n",
    "\n",
    "> 내적의 값이 클수록 유사하지 않은 것\n",
    "\n",
    "2. Loss function을 고려\n",
    "\n",
    "> 0보다 작을 수 없는 loss function -> 작아지기 위해서는 같은 레이블일 경우 $l$보다 큰 유사도 / 다른 레이블일 경우 u보다 작은 유사도\n",
    ">\n",
    "> $W$의 값 자체가 너무 커지는 것을 방지하기 위해서 Frobenius norm을 사용"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22cac1e8",
   "metadata": {},
   "source": [
    "하지만 위의 두 방법은 모두 하나의 행렬 $W$를 기반으로 한 선형 방법임 -> 변환의 표현력이 너무 단순함 -> 복잡한 변환을 생각할 필요가 있음 (초기의 방법임. 어떤 문제는 잘 안될 수 있음)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad823c7c",
   "metadata": {},
   "source": [
    "## 4. ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a6e9d93",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a381f223",
   "metadata": {},
   "source": [
    "## 1. AI에 대한 개괄적 설명"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41668ec1",
   "metadata": {},
   "source": [
    "### **A. 인공지능**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "600ab4b6",
   "metadata": {},
   "source": [
    "명확하게 정리된 유일한 정의는 없음\n",
    "\n",
    "`-` **AI에 대한 기술적 정의 (Technical definition)**:\n",
    "* 인간의 오감과 관련된 정보를 통합하여 분석, 학습, 예측\n",
    "* 의사결정 수행\n",
    "* 새로운 정보 학습 시 이전에 배운 정보를 유지하여 학습 가능: Continual Learning $\\to$ 새로운 태스크 데이터 학습 시 기존의 특정 태스크 정보가 점점 잊혀지는데, 이를 해결\n",
    "* 언어 처리와 메타 러닝 등을 수행할 수 있음"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74a73407",
   "metadata": {},
   "source": [
    "`-` 뇌과학 관점에서의 인공지능\n",
    "\n",
    "* Neural Network\n",
    "* 인간의 뇌를 모방"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f434d988",
   "metadata": {},
   "source": [
    "`-` 공학적 관점에서의 인공지능\n",
    "\n",
    "* XOR 문제의 해결을 위한 Multi-Layer-Perceptron\n",
    "* 통계학에서의 비선형 모델링 $y = f(x) + \\epsilon$ -> $f$의 설계\n",
    "* MLP $f = g_2 \\circ g_1$ : 미분 어려움, 해석에서 문제 있음\n",
    "> Complexity 훨씬 높음, 다양한 문제에 적용 가능 $\\to$ DNN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a1a16d5",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "`-` Application Example\n",
    "\n",
    "* Precision Medicine: 의료의 개인화 Personalization\n",
    "* Virtual Assistant: 가상 비서\n",
    "* Expert System\n",
    "* Auto Driving"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4049e277",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "* 추론 Reasoning\n",
    "* 자율적인 의사결정 및 작업 수행 Agent\n",
    "* Physical AI\n",
    "* Computer Vision/Speech/Expert System은 이미 인간을 능가하였음\n",
    "* Continuous learning/Meta learning/Reinforcement learning에서 상당한 발전"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b423a56",
   "metadata": {},
   "source": [
    "### **B. DNN**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91534ac8",
   "metadata": {},
   "source": [
    "`-` Simple DNN (Multi-Layer Perceptron; MLP)\n",
    "\n",
    "$$f({\\boldsymbol x}) = a(g_L \\circ g_{L-1} \\circ \\cdots \\circ g_1 ({\\boldsymbol x}))$$\n",
    "\n",
    "* $g_l(\\boldsymbol x) = \\sigma ({\\boldsymbol W_l \\boldsymbol x +  \\boldsymbol b_l})$이며, 해당 함수 $f$는 레이블 예측에 활용됨. 파라미터를 통해 학습되는 함수.\n",
    "* $\\sigma$는 활성화 함수(activation function)이며, $a(\\cdot) = {\\boldsymbol W_a ~ \\cdot} + {\\boldsymbol b_a}$는 스칼라 함수 또는 벡터 함수임(netout 벡터를 반환)\n",
    "\n",
    "$$\\begin{bmatrix} h_1 \\\\ h_2 \\end{bmatrix} = \\begin{bmatrix} w_{11} & w_{12} \\\\ w_{21} & w_{22} \\end{bmatrix} \\begin{bmatrix} x_1 \\\\ x_2 \\end{bmatrix}$$\n",
    "\n",
    "> 단순 레이어 변환. 선형 변환임: $\\boldsymbol W_l  \\boldsymbol x$의 형태\n",
    "\n",
    "$$\\begin{bmatrix} h_1 \\\\ h_2 \\end{bmatrix} = \\begin{bmatrix} w_{11} & w_{12} \\\\ w_{21} & w_{22} \\end{bmatrix} \\begin{bmatrix} x_1 \\\\ x_2 \\end{bmatrix} \\overset{\\sigma}{\\to} \\begin{bmatrix} \\sigma (h_1) \\\\ \\sigma (h_2) \\end{bmatrix}$$\n",
    "\n",
    "> 해당 선형 변환에 ReLU, sigmoid 등의 비선형 변환(activation function)을 추가하여 복잡한 형태를 만들어냄. $W$의 차원은 자유롭게 설정 가능"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b8ea660",
   "metadata": {},
   "source": [
    "`-` 인간의 뉴런과 DNN의 차이\n",
    "\n",
    "* **Activation** : 전기 신호 $\\approx$ 활성화 함수\n",
    "> 인간의 뇌의 시냅스 연결 - 무작위적, 비정형\n",
    ">\n",
    "> DNN의 퍼셉트론 간 연결 - 선형적?, 정형\n",
    "\n",
    "* **역전파 backpropagation**\n",
    "> 인간의 뇌 - 전체를 바꾸지 않고 일부만 변경하는 것이 가능\n",
    ">\n",
    "> DNN - 개별 weight만 바꿀 수 없음. 모든 뉴런을 다 변경해야 함 $\\to$ 비효율적, complexity 제약"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8045076f",
   "metadata": {},
   "source": [
    "`-` **Loss function**\n",
    "\n",
    "$$l(y, f({\\boldsymbol x}))$$\n",
    "\n",
    "* $l$은 일반적으로 convex function을 가정: CrossEntropy, MSE\n",
    "* $f(x)$가 정해져 있다면 loss function 자체만으로는 convex 하지만, $f$의 형태가 $\\theta$에 의해 바뀌기 때문에 loss function은 convex하지 않아 최적화가 어려움\n",
    "* 신경망의 앞부분은 Feature Extractor의 역할, 뒷부분은 손실 측정의 역할\n",
    "* $\\theta$의 비중이 압도적으로 큼. 즉, Feature extractor가 중요한 정보를 가지고 있음."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f37bf685",
   "metadata": {},
   "source": [
    "`-` 다양한 활용\n",
    "\n",
    "* **CNN**: `Convolution Kernel`을 도입하여 엣지 탐색, characterize로 이미지를 신경망이 더 잘 이해할 수 있도록 도움\n",
    "* **Shallow NN**: hidden layer가 두 개 이하인 경우 사용하기도 하는 표현\n",
    "* **Gradient vanishing**: Activation funciton 중 `sigmoid`,`tanh`는 각각 최대 편미분 값이 0.25, 1이기 때문에 레이어가 깊어질 수록 편미분 값들이 반복적으로 곱해지면서 1보다 작아지게 되고 기울기가 소실되도록 한다. 따라서 `ReLU`, `leaky ReLU`와 같이 적당한 범위 내에 값을 가질 수 있도록 하는 활성화 함수를 선호한다.\n",
    "* **Batch normalization**: 배치 단위로 입력을 정규화. 파라미터 스케일에 대한 민감도를 낮추는 역할\n",
    "* **Dropout**: 인간의 뇌가 랜덤하게 connection된다는 점을 모방하여 학습을 부드럽게 만듦\n",
    "* **Skip connection**: 레이어 연결 과정에서 몇 개의 층을 스킵하여 그래디언트 계산이 쉽도록 만듦\n",
    "* **Regularization**: 손실함수에 패널티를 추가하여 파라미터 크기를 너무 크지 않도록 억제"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08c86cb5",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "`-` **Stochastic Gradient Descent** : 랜덤 배치를 사용하는 경사 하강법\n",
    "\n",
    "* 전체 데이터 대신 무작위로 선택한 mini-batch를 사용하여 그래디언트를 계산, 작은 learning rate로 업데이트하는 과정을 반복\n",
    "* 일부의 데이터만 손실함수 계산에 사용함으로써 손실함수 개형을 바꿈\n",
    "* loss를 감소시키기는 어려우나, 특정 구간을 넘어가면 loss function의 flat 구간에 도착할 것으로 생각하고 최적화\n",
    "* 미니배치를 사용함에 따라 그래디언트에 노이즈를 발생시켜 bad local minimum에서 탈출시킬 수 있도록 도울 수 있음\n",
    "\n",
    "$$W_t \\leftarrow W_{t-1} - η \\nabla l_{W_{t-1}}(\\mathcal{B})$$\n",
    "\n",
    "* 이론적으로 learning_rate는 step $t$마다 일정한 규칙에 의해 줄어드는 것이 이상적임 $\\sum_t η_t = \\infty, ~ \\sum_t η_t^2 < \\infty \\to \\text{e.g.,} ~~ η_t = \\frac1t$\n",
    "* 실제로는 다양한 스케줄러가 사용되며, learning rate를 크게 만든 뒤 작게 조정하는 Cyclical learning rate는 NLP에서 사용하는 것이 좋다고 알려져 있음"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e3a4892",
   "metadata": {},
   "source": [
    "`-` **Data Loader**\n",
    "\n",
    "* 데이터의 용량이 매우 커서 GPU의 VRAM에 모두 올릴 수 없는 경우, 대용량의 데이터를 배치 단위로 나누어 순차적으로 GPU에 올려 학습\n",
    "* 배치를 사용하더라도 LLM 학습에서는 입력 시퀀스의 길이를 증가시켜 최대 출력 토큰 길이를 향상시키기 위해 VRAM이 더 많이 필요하게 됨\n",
    "* Data Loader는 CPU에서 미리 데이터를 준비한 뒤, GPU로 빠르게 전달하는 병렬 처리를 수행하여 효율적으로 배치를 관리"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11a3f584",
   "metadata": {},
   "source": [
    "## 2. Transfer Learning (단순 전이 학습)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a6d7bcf",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "### **A. Basic**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a1ceef8",
   "metadata": {},
   "source": [
    "`-` pre-trained model and target task\n",
    "\n",
    "* pre-trained model이 주어졌을 때, 입력 데이터의 변환된 표현을 획득 가능\n",
    "* 해당 표현은 새로운 문제에서 source와 target이 공통 요소를 가질 때 유용\n",
    "> DNN에서 feature extractor 역할을 하는 부분은 다른 곳에 활용해도 잘 작동하지 않을까란 아이디어\n",
    ">\n",
    "> General한 pre-trained model을 다른 도메인에 적용"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faf045a6",
   "metadata": {},
   "source": [
    "`-` Mathmetical Framework\n",
    "\n",
    "$T, S$가 Target, Source domain이라고 할 때,\n",
    "\n",
    "1. $g_i: X_s \\to Y_s$ hypothesis of source tasks. (함수의 형태가 이런 꼴일 것이라는 가설을 세우는 느낌으로 이해)\n",
    "2. $f: X_t \\to Y_t$ hypothesis of target task. 배우고 싶은 요소\n",
    "\n",
    "* common $c$, specific parts $w_i, v$로 hypothesis를 분해\n",
    "\n",
    "$$g_i = w_i \\circ c, ~ f = v \\circ c$$\n",
    "\n",
    "> $c$는 소스 데이터에서 학습 가능, $v$는 타겟 데이터로 학습 가능 $\\to$ $v$만 배우면 됨\n",
    ">\n",
    "> 대용량의 데이터셋으로 훈련된 모델 $g_i$와, $f$가 공유하는 특징이 클 수록 전이학습이 효과적이다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48551562",
   "metadata": {},
   "source": [
    "`-` Scratch, Freezing, Fine-Tuning\n",
    "\n",
    "* 소스 모델의 마지막 output layer를 제거하고, target task를 위한 additional layers를 부착하여 end-to-end 구조로 구성됨\n",
    "* Scratch: 전체 가중치를 랜덤 초기값으로 설정하고, target 데이터로 전체 모델을 학습. 전체 모델을 재훈련함으로써 데이터가 적은 경우 모형이 제대로 학습되지 못함\n",
    "* Freezing: 소스 모델의 가중치는 동결한 채, additional layers만 훈련\n",
    "* Fine-Tuning: 소스 모델의 가중치를 초기값으로 설정하고, target 데이터로 전체 모델을 학습\n",
    "* Hybrid: Feature Extractor(소스 모델)의 일부 레이어를 동결시키고, 일부 레이어만 기존 가중치를 초기값으로 하여 additional layers와 같이 훈련. 어떤 지점에서 구간을 잘라야 할 지 결정하는 문제가 있으므로, 일반적으로 활용되지는 않음"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76bdcf06",
   "metadata": {},
   "source": [
    "### **B. Mathmatical Frameworks**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49f98346",
   "metadata": {},
   "source": [
    "`-` Risk of Transfer Learning\n",
    "\n",
    "$C(\\mathcal{C}), C(\\mathcal{V})$를 $\\mathcal{C}, \\mathcal{V}$의 복잡도 측정값이라 하고, $t, n$을 각각 소스 태스크의 수와 개별 소스 태스크에서의 샘플 사이즈로, $m$을 타겟 태스크의 샘플 사이즈라고 할 때\n",
    "\n",
    "$$\\tilde{O} \\left( \\frac{1}{\\nu} \\sqrt{\\frac{C(\\mathcal{C}) + t C(\\mathcal{V})}{nt}} + \\sqrt{\\frac{C(\\mathcal{V})}{m}} \\right)$$\n",
    "\n",
    "* 현재 target sample size인 $m$을 키우기 어려운 상황이므로, 완전히 다른 태스크인 $\\mathcal{V}$의 비중이 줄어들어야 한다. 즉, 소스와 타겟의 공통 태스크 비중이 커야 복잡도가 줄어든다.\n",
    "* 또한 소스 모델이 큰 모델일 수록 $nt$의 값이 커져 복잡도가 감소한다.\n",
    "* 즉, 좋은 소스 모델을 찾아서 타겟 문제를 해결하면 된다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8652c6b",
   "metadata": {},
   "source": [
    "`-` Transfer Learning과 관련된 문제\n",
    "\n",
    "* Meta Learning: 학습을 위한 학습. 여러 언어들을 배운 모델이 다른 언어를 쉽게 학습할 수 있을까?\n",
    "* Adaptive Learning: 배운 지식을 공통점이 조금 있는 다른 분야에서 활용할 수 있을까?\n",
    "* OOD: 학습 데이터의 분포와 평가 데이터의 분포가 다른 상황에서 모델이 정상 작동할 수 있을까? 현실에서의 문제 해결에 매우 중요."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37786e0e",
   "metadata": {},
   "source": [
    "## 3. Transfer Learning (2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "673e57aa",
   "metadata": {},
   "source": [
    "### **A. Domain Adaptation**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fd0d2e4",
   "metadata": {},
   "source": [
    "`-` Definition\n",
    "\n",
    "* 소스 도메인의 데이터로 훈련된 모델을 관련된 다른 타겟 도메인에서 잘 작동하도록 만드는 기술\n",
    "\n",
    "> Superviesd to Supervised\n",
    ">\n",
    "> 적은 라벨의 지도학습을 많은 라벨의 지도학습으로\n",
    ">\n",
    "> Unsupervised to Unsupervised: PCA 변환 행렬을 다른 데이터에 그대로 사용할 수 있는가?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7461c3a5",
   "metadata": {},
   "source": [
    "`-` Examples\n",
    "\n",
    "* 특정 지역의 저해상도의 이미지와 레이블 + 레이블링 되지 않은 고해상도 이미지\n",
    "* 다수의 레이블로 처리된 시뮬레이션 이미지 + 더 적은 레이블의 현재 이미지"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3abb5a2",
   "metadata": {},
   "source": [
    "`-` Mathematical formulation\n",
    "\n",
    "$$\\begin{align} & p_t(x) \\neq p_s(x) \\\\\n",
    "& p_t(T(x)) = p_s(T(x)) \\\\\n",
    "& p_t(y | T(x)) = p_s(y | T(x))\n",
    "\\end{align}$$\n",
    "\n",
    "$p_t,~ p_s$가 타겟/소스 도메인의 분포이고, $T$를 변환이라고 할 때, 타겟과 소스의 분포를 일치시키는 변환 $T$를 찾는다.\n",
    "\n",
    "* 서로 다른 분포의 소스/타겟 도메인이 존재할 때, $T$라는 변환은 각 도메인의 데이터 x에 대하여 $T(x)$가 같은 분포를 가지도록 만든다.\n",
    "* 해당 변환을 찾을 수 있다면, 각 도메인에서 동일한 변환값이 주어졌을 때 label의 조건부 확률 분포는 동일해야 한다 $\\to$ 변환하여 분류할 수 있는 형태로 주어진다.\n",
    "\n",
    "> 현실에서 마지막은 이상적인 경우이며, $T$를 찾는 문제도 매우 어렵다. 보통 $T$를 찾고, 마지막 조건에 근접하도록 regularization 한다.\n",
    ">\n",
    "> 두 데이터가 하나의 확률 분포를 가지고 있으면 동일한 예측을 수행할 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f09bd627",
   "metadata": {},
   "source": [
    "`-` **Metric Learning**\n",
    "\n",
    "1. 두 점 $x_s^i,~ x_t^i$ 사이의 거리를 고려\n",
    "\n",
    "$$d_W (x_s^i, x_t^i) = (x_s^i - x_t^i)^{\\top} W (x_s^i - x_t^i)$$\n",
    "\n",
    "> 유클리디안 거리의 제곱 수식에 positive semi-definite metrix $W$를 넣음.\n",
    "\n",
    "2. $W$는 $W^{\\frac12}$로 나타날 수 있으므로, 위 수식은 $W^{\\frac12}x_s^i$와 $W^{\\frac12}x_t^i$간 거리: 각 점을 변환한 상태에서의 거리라고 말할 수 있음. (선형 변환)\n",
    "\n",
    "3. $x_s^i,~ x_t^i$의 레이블이 같다면, 변환 후 거리가 $u$를 넘기지 않아야 하며, 레이블이 다르다면 변환 후 거리가 $l$보다 길어야 함.\n",
    "\n",
    "$$\\text{arg} \\min_{W ⪰ 0} Tr(W) - \\log \\text{det} (W) ~~ s.t.$$\n",
    "\n",
    "$$d_W (x_s^i, x_t^i) ≤ u ~~~~ \\text{if} ~~ y^i = y^j$$\n",
    "\n",
    "$$d_W (x_s^i, x_t^i) ≥ l ~~~~ \\text{if} ~~ y^i \\neq y^j$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c9f5616",
   "metadata": {},
   "source": [
    "`-` **Asymmetric Transformations**\n",
    "\n",
    "1. 내적 기반 유사도를 사용 (Inner product-based similarity)\n",
    "\n",
    "$$\\text{sim}_W (x_s^i, x_t^i) = {x_s^i}^{\\top} W x_t^i$$\n",
    "\n",
    "> 내적의 값이 클수록 유사하지 않은 것\n",
    "\n",
    "2. Loss function\n",
    "\n",
    "$$\\mathbb{I}(y_s^i = y_t^i) (\\max(0, l - {x_s^t}^{\\top} W x_t^i))^2 + \\mathbb{I}(y_s^i \\neq y_t^i) (\\max(0, {x_s^i}^{\\top} W x_y^i - u))^2 + \\lambda ||W||_F$$\n",
    "\n",
    "* 0보다 작을 수 없는 Loss function\n",
    "* 같은 레이블일 경우 l보다 큰 유사도를, 다른 레이블일 경우 u보다 작은 유사도를 가져야 손실을 작게 유지 가능\n",
    "* $W$의 값 자체가 너무 커지는 것을 방지하기 위해 Frobenius norm을 사용: 모든 원소의 제곱합의 제곱근"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22cac1e8",
   "metadata": {},
   "source": [
    "위의 두 방법은 모두 하나의 행렬을 기반으로 한 선형 방법이므로, 비선형 변환이 필요한 문제에서 잘 동작하지 못할 가능성이 높다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67d57da1",
   "metadata": {},
   "source": [
    "`-` **Maximum Mean Discrepancy**: Unsupervised Domain Adaptation. 두 분포 간 거리를 측정하는 metric\n",
    "\n",
    "* 두 분포가 같은지를 판단하기 위한 가장 단순한 방법: Moment Matching\n",
    "> 두 도메인 $X, Y$의 $1, 2, \\cdots, m$차 적률이 동일한지를 검사한다. 이론적으로 모든 적률이 존재하고 수렴한다는 조건 하에서 $m \\to \\infty$일 때 이것이 성립된다면 $p_s = p_t$라 말할 수 있다.\n",
    "\n",
    "* MMD의 아이디어: RKHS인 $H$ 상에서 $\\text{MMD}(X, Y) = \\underset{f \\in H, ~ ||f|| ≤ 1}{\\sup} ~ E[f(X)] - E[f(Y)] \\to 0$이면, $X, Y$의 분포는 동일하다. $\\to$ $H$에서의 변환 후 적률 차이의 상한이 0이면 둘은 동일...\n",
    "\n",
    "* Sample MMD: Kernel Trick (Inner Product ↔ Kernel. 고차원 매핑의 내적은 커널로 표현할 수 있음)\n",
    "\n",
    "$$⟨\\phi(x),\\phi(y)⟩ = K(x,y)$$\n",
    "\n",
    "$$\\text{MMD}(\\{x_i\\}_{i=1}^n, ~ \\{y_i \\}_{i=1}^m)^2 = \\sum_{i, j} K(x_i, x_j)/n^2 + \\sum_{i, j} K(y_i, y_j)/m^2 - 2 \\sum_{i, j} K(x_i, y_i)/mn$$\n",
    "\n",
    "> 변환된 소스-타겟 샘플에 대하여 평균적으로 $K(x_i, x_j) = K(x_i, y_j) = K(y_i, y_j)$가 된다면 sample MMD는 0에 가까워진다.\n",
    ">\n",
    "> Exponential 형태의 커널 $K(x, y) = \\exp(-\\frac{(x-y)^2}{\\sigma})$등을 사용하면 충분한 표현력을 가지며, 분포의 동질성을 식별할 수 있다. 즉, sample MMD(X, Y)를 최소화하는 학습을 통해 두 분포를 같게 만들 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54a74ea0",
   "metadata": {},
   "source": [
    "`-` **Sample Reweighting**: Unsupervised DA\n",
    "\n",
    "$$\\text{arg} \\min_{\\beta} || \\frac{1}{n} \\sum_{i=1}^n \\beta_i \\phi (x_s^i) - \\frac{1}{m} \\sum_{i=1}^m \\phi (x_t^i)||^2$$\n",
    "\n",
    "$$s.t. ~~ \\beta_i \\in [0, B], ~ i \\in [n], ~ |\\sum_{i=1}^n \\beta_i - n| ≤ n\\epsilon$$\n",
    "\n",
    "* 파라미터 $\\beta_i$가 추가된 MMD 손실 함수로 분포를 같게 만듦\n",
    "* $\\beta_i$를 곱하여 소스 샘플별 가중치를 조정함으로써 두 도메인 데이터의 분포를 맞춤"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c8b837b",
   "metadata": {},
   "source": [
    "`-` **Sample Selection**: Sample Reweighting의 확장\n",
    "\n",
    "$$\\text{arg} \\min_{\\alpha} || \\frac{1}{\\sum_i \\alpha_i} \\sum_{i=1}^n \\alpha_i \\phi (x_s^i) - \\frac{1}{m} \\sum_{i=1}^m \\phi (x_t^i)||^2$$\n",
    "\n",
    "$$s.t. ~~ \\alpha_i \\in \\{0, 1\\}, ~ i \\in [n], ~ \\sum_i \\frac{1}{\\sum_i \\alpha_i} \\alpha_i y_c^i = \\frac{1}{n} \\sum_i y_c^i$$\n",
    "\n",
    "* 단순 연속형 가중치 $\\beta_i$를 주는 대신, 선택 변수 $\\alpha_i \\in \\{0, 1\\}$을 부여하여 유사한 샘플만 선택\n",
    "* 손실 계산에 사용할 샘플 선택 후 레이블의 비율이 원래와 같게 유지되도록 제한하여 학습 시 클래스 비율 변경에 의해 모델이 왜곡되지 않도록 함\n",
    "> 타겟 분포와 유사하면서, 레이블 비율도 유지하는 소스 샘플만 선택"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c942dd9",
   "metadata": {},
   "source": [
    "`-` **Domain Invariant Projection (DIP)**\n",
    "\n",
    "$$\\text{arg} \\min_{W} D_{\\text{MMD}}^2 (W^{\\top} X_s, W^{\\top} X_t)$$\n",
    "\n",
    "$$s.t ~~ W^{\\top}W = I$$\n",
    "\n",
    "* 정직교 orthogonal 행렬인 $W$로 두 도메인을 선형 변환한 뒤, sample MMD를 계산하고 이를 최소화하는 $W$를 탐색"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b99cbf6",
   "metadata": {},
   "source": [
    "`-` **Domain Invariant Projection (DIP)**\n",
    "\n",
    "* 선형 사상인 $W$를 이용하여 두 도메인을 같은 공간으로 사영한 뒤, 사영된 공간에서 MMD를 다시 최소화\n",
    "* 선형 변환된 것을 한번 더 MMD로 재변환. $W_x \\to \\phi(W_x)$\n",
    "* 모형 자체가 비선형인 경우(DNN 등)가 들어오면, 선형 변환이 깨짐. 따라서 비선형으로 변환하여 성능을 유지"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de9dfa44",
   "metadata": {},
   "source": [
    "`-` **Correlation Approach CORAL**\n",
    "\n",
    "* 소스와 타겟의 correlation을 맞춤\n",
    "* 소스 피쳐를 de-correlate 이후, 타겟 피쳐의 공분산을 이용해 re-correlate\n",
    "* 도메인의 분포가 정규분포를 벗어나면 해당 접근이 잘 동작하지 않을 수 있음"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b516eea3",
   "metadata": {},
   "source": [
    "### **B. Knowledge Distillation**\n",
    "\n",
    "기존 고성능 모델보다 간단한 아키텍쳐로 조금 성능이 떨어지는 고효율의 모델을 구성"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f5dc527",
   "metadata": {},
   "source": [
    "`-` **Pre-trained Model의 비효율성**\n",
    "\n",
    "* ReLU activation: activation이 0일 경우, 이전 뉴런의 정보가 넘어가지 않고, 그 뒤로도 연결이 계속 끊어지게 된다. 이는 뉴런 간 connection이 대다수 유지되지 못하여 불필요한 파라미터가 많음을 의미한다.\n",
    "* KD는 고성능의 대형 모델(Teacher)과 비슷한 퍼포먼스가 나오는 작은 모델(Student)를 구축하는 것에 초점을 맞춘다. 즉, 복잡한 모델에서 얻은 지식을 더 단순한 모델로 응축하는 과정이다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6631f5eb",
   "metadata": {},
   "source": [
    "`-` **Distillation Loss**\n",
    "\n",
    "> Teacher와 Student의 출력 확률값을 직접 맞추는 것이 아닌, Teacher가 예측한 클래스의 확률 분포를 Student가 학습하도록 유도\n",
    "\n",
    "* Response-based approaches: Teacher와 Student의 최종 출력 확률의 유사성을 손실에 추가 (KL Divergence)\n",
    "\n",
    "$$\\sum_{c=0}^C p_s^c \\log \\frac{p_s^c}{p_t^c}$$\n",
    "\n",
    "* Feature-based: 확률 벡터 산출 이전의 Feature Layer 값이 유사하도록 만듦. 일반적으로 Penultimate Layer를 사용 (마지막에서 두 번째)\n",
    "\n",
    "$$\\tau \\frac{f}{||f||}$$\n",
    "\n",
    "> 두 벡터 간 스케일이 다르기 때문에 상수와 norm으로 스케일을 조정한 뒤 비교\n",
    "\n",
    "* Relation-based: 레이어 간 correlation을 유사하게 만듦. 2개 레이어 간 내적이 Teacher와 Student간에 유사하도록 만들 수 있음"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bd3fabb",
   "metadata": {},
   "source": [
    "`-` 세 방법론의 차이\n",
    "\n",
    "* Response-based / Feature-based: 정보가 말단 레이어에 몰려있을 것이라고 생각함\n",
    "* Relation-based: Feature가 다음 레이어로 넘어가는 과정이 유사하도록 만듦\n",
    "* 최초 입력값, Input은 Attribute라고 한다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8c9b1a6",
   "metadata": {},
   "source": [
    "`-` Other categories\n",
    "\n",
    "* Online Learning: 새로 들어온 데이터를 추가했을 때, 어떻게 바꿔야 수학적으로 엄밀한지를 분석하여 조정. 새로 들어온 데이터 단독으로 모델을 구성하여 가중치를 변경. Convex에서는 잘 작동하나, non-Convex 문제에서의 이론적인 배경은 없음.\n",
    "* self-distillation: 자기 자신이 teacher이자 student로써 자기지도적 형태\n",
    "* multi-teacher: 여러 teacher를 사용하여 student를 학습\n",
    "* adversatial approach: 적대적 모형을 동시에 활용"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc500df3",
   "metadata": {},
   "source": [
    "### **C. 실습 내용**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23f68777",
   "metadata": {},
   "source": [
    "`-` **Temperature Scaling**\n",
    "\n",
    "* Overconfidence\n",
    "> 분류기의 출력값은 소프트맥스 함수를 통해 확률로 변환되고, 보통 한 개의 클래스에 대한 확률만 1에 가까워지고 나머지는 거의 0이 되는 현상이 발생\n",
    ">\n",
    "> 모델이 예측은 잘 수행하더라도, Calibration이 깨져서 정답일 확률을 신뢰할 수 없음. 따라서 해당 확률 벡터로 Student를 보정하는 것에 문제가 있음\n",
    "\n",
    "* Softmax의 sharpness를 조절\n",
    "\n",
    "$$\\frac{\\exp (f_i / \\tau)}{\\sum_i \\exp (f_i / \\tau)}$$\n",
    "\n",
    "> $\\tau$가 1보다 클 수록 확률의 차이가 완화"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1259840",
   "metadata": {},
   "source": [
    "`-` **Cosine Loss**\n",
    "\n",
    "* hidden layer 비교 시 두 벡터의 스케일이 다를 수 있으므로, 단순 유클리드 거리를 비교하는 것 대신 방향을 비교할 수 있는 Cosine Loss를 도입\n",
    "* 코사인 유사도에 음수를 취하여 벡터가 같은 방향일수록 손실이 0에 가까워짐"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad823c7c",
   "metadata": {},
   "source": [
    "## 4. Baesian Basics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21e10f5f",
   "metadata": {},
   "source": [
    "### **A. Bayesian Intro**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e54f1ab",
   "metadata": {},
   "source": [
    "`-` **Inference / prediction**\n",
    "\n",
    "* Inference: 기저의 분포를 식별. $\\to$ 샘플로부터 모집단에 대한 여러 정보 및 관계를 알아내는 것. 추정.\n",
    "* Prediction: 예측의 영역. $\\to$ 베이지안에서의 중요 개념. 확률적으로 prediction의 개념을 정교화\n",
    "* hypothesis: 기계학습에서는 모델의 의미로서 사용되는 경향 존재"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8976e262",
   "metadata": {},
   "source": [
    "`-` **Bayes Theorem.**\n",
    "\n",
    "$$P(Z|X) = \\frac{P(X|Z)P(Z)}{P(X)}$$\n",
    "\n",
    "* $Z$: unknown random, 관측 불가능. $X$: $Z$에 의해서 결정, 관측 가능.\n",
    "* 관측되지 않은 $Z$의 확률을 관측된 사건 $X$로 표현하는 것. Conditional Probability를 Inverse-Probability로 표현\n",
    "* $Z$를 고정된 unknown quantity로 보면 다루기 어려우나, 확률 변수로 취급하면 다루기 쉽다. 따라서 베이즈는 이를 확률 변수로 취급하여 분포로 나타낼 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a96e6cba",
   "metadata": {},
   "source": [
    "`Example`: 하얀 공과 검은 공을 복원 추출한 랜덤 샘플이 주어졌을 때, 검은 공을 뽑을 확률을 구하는 문제\n",
    "\n",
    "$$R_i \\sim \\text{Bernoulli}(w), ~ i \\in [n], ~ w \\sim \\text{Beta}(1, 1)$$\n",
    "\n",
    "$$p(r=1|R_1, R_2, ..., R_n)?$$\n",
    "\n",
    "* Uniform Prior (`Beta(1, 1) == U(0, 1)`)\n",
    "\n",
    "\n",
    "`Solution`\n",
    "\n",
    "$$\\begin{align}\n",
    "p(w ~ | ~ R_1, R_2, \\cdots, R_n) & = \\frac{p(R_1, R_2, \\cdots, R_n ~ | ~ w) p(w)}{p(R_1, R_2, \\cdots, R_n)} \\\\\n",
    "& = \\frac{L(w ~ | R_1, R_2, \\cdots, R_n) p(w)}{p(R_1, R_2, \\cdots, R_n)} \\\\\n",
    "& \\propto L(w ~ | R_1, R_2, \\cdots, R_n) p(w) \\\\\n",
    "& = w^{\\sum_{i=1}^n R_i} \\times (1-w)^{n - \\sum_{i=1}^n R_i}\n",
    "\\end{align}$$\n",
    "\n",
    "* 해당 수식은 $Beta(\\sum R_i + 1, n - \\sum R_i + 1)$의 확률밀도함수에 베타 함수 $B(\\sum R_i + 1, n - \\sum R_i + 1) = \\frac{\\Gamma (\\sum R_i + 1) \\Gamma (n - \\sum R_i + 1)}{\\Gamma (n+2)}$를 곱한 형태와 동일하므로, 이를 나누어 확률분포의 형태로 보정해주면,\n",
    "\n",
    "$$p(w ~ | ~ R_1, R_2, \\cdots, R_n) = \\frac{\\Gamma (n+2)}{\\Gamma (\\sum R_i + 1) \\Gamma (n - \\sum R_i + 1)} w^{\\sum R_i}\\times (1-w)^{n - \\sum R_i}$$\n",
    "\n",
    "* 그러므로,\n",
    "\n",
    "$$\\begin{align}\n",
    "p(r = 1 ~ | ~ R_1, R_2, \\cdots, R_n) & = \\int_0^1 p(r=1, w ~ | ~ R_1, R_2, \\cdots, R_n) dw \\\\\n",
    "& = \\int_0^1 p(r = 1 ~ | ~ w, R_1, R_2, \\cdots, R_n) \\times p(w ~ | ~ R_1, R_2, \\cdots, R_n) dw \\\\\n",
    "& = \\int_0^1 w \\times \\frac{1}{B(\\sum_i R_i + 1, n - \\sum_i R_i + 1)} w^{\\sum_i R_i}(1-w)^{n - \\sum_i R_i} dw \\\\\n",
    "& = \\frac{1}{B(\\sum_i R_i + 1, n - \\sum_i R_i + 1)} \\int_0^1 w^{\\sum_i R_i + 1} (1-w)^{n - \\sum_i R_i} dw \\\\\n",
    "& = \\frac{B(\\sum_i R_i + 2, n - \\sum_i R_i + 1)}{B(\\sum_i R_i + 1, n - \\sum_i R_i + 1)} \\\\\n",
    "& = \\frac{\\Gamma (\\sum_i R_i + 2) \\Gamma (n - \\sum_i R_i + 1)}{\\Gamma (n + 3)} \\times \\frac{\\Gamma (n+2)}{\\Gamma (\\sum R_i + 1) \\Gamma (n - \\sum R_i + 1)} \\\\\n",
    "& = \\frac{(\\sum_i R_i + 1)! (n - \\sum_i R_i)!}{(n+2)!} \\times \\frac{(n+1)!}{(\\sum_i R_i)! (n - \\sum_i R_i)!} \\\\\n",
    "& = \\frac{\\sum_i R_i + 1}{n+2}\n",
    "\\end{align}$$\n",
    "\n",
    "* $\\hat p$: MLE, $\\hat p_B$: Baysian\n",
    "> 단순 표본 평균을 사용하는 MLE와는 Prior 때문에 추정량이 다름\n",
    "* Prior의 평균인 0.5의 방향으로 $\\hat p$를 당긴 것이 $\\hat p_B$이다. : Shirinkage Effect\n",
    "> Prior를 어떻게 설정하는지에 따라 Shirinkage 방향이 바뀜\n",
    "* Data dominating: $n$과 $\\sum_i R_i$가 충분히 크다면, Prior의 영향이 작아진다.\n",
    "* sample mean을 사용하는 것보다 prior를 잘 사용함으로써 여러 상황에서의 문제를 줄일 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14b9210b",
   "metadata": {},
   "source": [
    "### **B. Prior, Model, and Posterior**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88a205af",
   "metadata": {},
   "source": [
    "`-` **Notations**\n",
    "\n",
    "|Category|Expression|Description|\n",
    "|:-:|:-:|:-|\n",
    "|Prior|$p(\\theta)$|파라미터 $\\theta$에 확률|\n",
    "|Likelihood (Model)|$L(\\theta) = p(y ~ \\| ~ \\theta)$|$y$를 고정된 스칼라로 취급할 때, $\\theta$의 값에 따라 변화하는 가능도|\n",
    "|Posterior|$p(\\theta ~ \\| ~ y)$|$y$가 주어졌을 때의 posterior distribution|"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b98cc08",
   "metadata": {},
   "source": [
    "`-` **Prior**\n",
    "\n",
    "* 관측값 없이 고려된 파라미터의 분포. 파라미터에 대한 사전 지식\n",
    "* **Construction method**\n",
    "1. 해당 도메인 전문가들로부터의 histogram, elicitation등을 통해 분포를 파악\n",
    "2. 평균과 분산 정도만 파악한 뒤, 편의상 정규/베타 분포를 택함\n",
    "3. non-informative prior를 사용: prior의 영향력을 최소화하고, Likelihood가 지배적이도록 만듦\n",
    "> Example: position(mean) 파라미터 $\\mu$와, 스케일 파라미터 $\\sigma$에 대해 $p(\\mu) \\propto 1, ~ p(\\sigma) \\propto 1/\\sigma$. 분포의 위치가 바뀌어도 확률값이 동일하며, 스케일이 바뀌어도 형태가 유지되는 모습. 이는 일반적으로 적분해도 1이 나오지 않는다. (improper)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d02f9127",
   "metadata": {},
   "source": [
    "* Construction\n",
    "> 1. 해당 도메인의 전문가들이 모여 분포를 파악 elicitation\n",
    "> 2. 평균, 분산만 대충 파악하고 가우시안/베타 분포...\n",
    "> 3. **non-informative**: prior가 gaussian이면 mean에 몰리므로 데이터가 들어와도 $L(\\theta|y)$가 왜곡될 수 있음. uniform이여도 구간이 정해져 있어서 곤란... 그냥 $p(w) = c, -\\infty < w < \\infty$를 사용. $\\to$ posterior를 들여왔을 때 적분해서 1이 되기만 하면 충분하다...\n",
    ">\n",
    ">   Example: $p(\\mu) ∝ 1, p(\\sigma) ∝ \\frac{1}{\\sigma} \\to$ scale이 바뀌어도 형태가 계속해서 유지됨... 적분해도 1이 안나옴\n",
    "\n",
    "* 샘플이 커지면 prior effect가 작아짐 ㅇㅇ\n",
    "* Complex가 높은 모델(DNN: Weight + Bias에 모두 Prior를 줘야 함)의 경우, 샘플이 Prior Effect를 압도할 수 없게 됨\n",
    "> 이때문에 베이지안에서 딥러닝을 사용하기 어려움... non-informative도 적분이 안되는 경우도 있음..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bd6a7db",
   "metadata": {},
   "source": [
    "`-` Posterior and usage of its components.\n",
    "\n",
    "$$p(\\theta | y) = \\frac{p(y|\\theta)p(\\theta)}{p(y)} := \\frac{L(\\theta|y) p(\\theta)}{p(y)} \\propto L(\\theta | y)p(\\theta)$$\n",
    "\n",
    "* $p(y)$는 상수 같은 거니까 그대로 둬도 됨\n",
    "* $\\theta$가 argument라는 점을 명시해주기 위해서 Likelihood로 정의를 바꿈\n",
    "* 커널만 알면, 상수로 취급되는 부분은 전부 유도해낼 수 있음 $\\to$ 어차피 적분값으로 나누면, 확률밀도함수의 기본 성질을 만족하게 됨\n",
    "\n",
    "> Prior에 제약을 걸면, Posterior에도 그 제약이 반영됨. 너무 강한 제약을 걸어버리면 == prior를 이상한 형태로 집어넣거나 잘못 입력했으면, 비정상적인 결과가 나올 수 있음"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "829b3e6e",
   "metadata": {},
   "source": [
    "`-` Model or Likelihood\n",
    "\n",
    "* 데이터는 posterior에 Likelihood로 영향을 줄 수 있음\n",
    "* 데이터의 크기가 커질수록 Posterior에 데이터가 주는 영향력이 커짐 ㅇㅇ\n",
    "\n",
    "`-` Posterior\n",
    "\n",
    "* random parameter의 posterior $\\to$ 분포를 추정하는 문제\n",
    "* Posterior는 분포임 (point estimator가 아님. 분포를 만들어버린 다음에 점과 구간을 뽑아내는 것. 훨씬 informative한 객체)\n",
    "> 분포를 근사할 때, pdf의 커널 정도로 샘플링하는 테크닉. 샘플로 population의 estimate를 계산"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1077d543",
   "metadata": {},
   "source": [
    "`-` Properties of posterior\n",
    "\n",
    "$y_1, y_2$가 관측되었을 때, $\\theta$의 posterior를 계산\n",
    "\n",
    "1. $p(\\theta | y_1, y_2) \\propto L(\\theta | y_1, y_2) p(\\theta) \\to p(y_2 | \\theta, y_1) p(\\theta | y_1)$\n",
    "\n",
    "> $p(\\theta) \\to p(\\theta | y_1) \\to p(\\theta | y_1, y_2) \\to \\cdots$의 방식으로 순차적인 업데이트가 가능\n",
    ">\n",
    "> posterior를 prior처럼 사용하는 방식으로, 온라인 러닝에서 유용하게 사용됨\n",
    "\n",
    "2. $p(\\theta | y) = k(\\theta)h(y) \\to h(y) = 1/ \\int k(\\theta)\\theta$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4b45525",
   "metadata": {},
   "source": [
    "### Example\n",
    "\n",
    "계산을 따라가는 것도 좋으나, 결과를 이해하는 것이 가장 중요"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7344595e",
   "metadata": {},
   "source": [
    "`-` Beta-binomial\n",
    "\n",
    "$$\\begin{align}\n",
    "y|\\theta & \\sim \\text{Binom}(n, \\theta) \\\\\n",
    "p(\\theta) & ≡ \\text{Beta}(\\theta, \\alpha, \\beta) = \\frac{\\Gamma(\\alpha) \\Gamma(\\beta)}{\\Gamma (\\alpha + \\beta)} \\theta^{\\alpha - 1}(1-\\theta)^{\\beta - 1} \\\\\n",
    "E[\\theta] & = \\frac{\\alpha}{\\alpha + \\beta}, ~ \\text{Var}(\\theta) = \\frac{\\alpha \\beta}{(\\alpha + \\beta)^2 (\\alpha + \\beta + 1)}\n",
    "\\end{align}$$\n",
    "\n",
    "> prior를 Beta분포로 함"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f23452d4",
   "metadata": {},
   "source": [
    "* Joint distribution of $p(y, \\theta) = p(y | \\theta)p(\\theta)$.\n",
    "\n",
    "> 베타 분포를 먹인 순간부터, 항이 정리됨\n",
    ">\n",
    "> 상수가 바뀌는 것은 나중에 처리하면 되고, $\\theta$에 대한 항만 정리하면...\n",
    "\n",
    "$$\\theta^{\\alpha + y - 1}(1 - \\theta)^{n-y +\\beta-1}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beaced13",
   "metadata": {},
   "source": [
    "* Posterior of $\\theta$ given $y$\n",
    "\n",
    "$$p(\\theta | y) \\propto \\theta^{\\alpha + y - 1}(1 - \\theta)^{n-y +\\beta-1} ≡ \\text{Beta}(\\theta | y + \\alpha, n - y + \\beta)$$\n",
    "\n",
    "> $E[\\theta | y] = \\frac{y + \\alpha}{n + \\alpha + \\beta} = \\frac{y}{n} \\times \\frac{n}{n + \\alpha + \\beta} + \\frac{\\alpha}{\\alpha + \\beta} \\times \\frac{\\alpha + \\beta}{n + \\alpha + \\beta} \\to$ $n$이 커질수록 prior effect가 줄어들고, data가 dominant해짐. posterior의 mean은 sample mean과 prior의 mean으로 이뤄짐\n",
    ">\n",
    "> $Var(\\theta | y) = O(\\frac{1}{n}) \\to$ 샘플이 커질수록 posterior의 분산이 작아짐. 즉, 분포가 한 점에 수렴. 보통 작아짐 ㅇㅇ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb069780",
   "metadata": {},
   "source": [
    "`-` Normal-normal in mean\n",
    "\n",
    "$$\\begin{align}\n",
    "y | \\theta & \\sim N(\\theta, \\sigma^2) \\\\\n",
    "\\theta & \\sim N(0, \\kappa \\sigma^2)\n",
    "\\end{align}$$\n",
    "\n",
    "> 단, $\\sigma^2$는 known scalar"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fb1b99b",
   "metadata": {},
   "source": [
    "* Joint distribution of $p(y, \\theta) = p(y | \\theta)p(\\theta)$\n",
    "\n",
    "> 어떻게든 $h(\\theta)$와 그 바깥의 것으로 나눔 (지수족 느낌으로다가)\n",
    ">\n",
    "> 정규 분포의 포맷으로 어떻게든 바꿈 ㅇㅇ\n",
    "\n",
    "$$p(\\theta | y) \\propto N(\\theta | y(1 + 1/\\kappa)^{-1}, (1 + 1/\\kappa)^{-1}\\sigma^2)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc744952",
   "metadata": {},
   "source": [
    "* Properties\n",
    "\n",
    "1. mean은 아래와 같이 표현될 수 있음\n",
    "\n",
    "$$y \\times \\frac{1}{1 + 1/\\kappa} + 0 \\times \\frac{1/\\kappa}{1 + 1/\\kappa}$$\n",
    "\n",
    "> Sample에서 계산한 $y$와, prior에서의 mean이 합쳐져 있음\n",
    "\n",
    "\n",
    "2. 각 통계량\n",
    "\n",
    "$$\\begin{align}\n",
    "E[\\theta | y] & = \\bar{y} \\times \\frac{n}{n + 1/\\kappa} + \\mu_0 \\times \\frac{1/\\kappa}{n + 1/\\kappa} \\\\\n",
    "\\text{Var}(\\theta | y) & = \\frac{\\sigma^2}{n + 1/\\kappa}\n",
    "\\end{align}$$\n",
    "\n",
    "> 분산을 줄이는 효과가 있음: Prior가 Overfitting을 막을 수 있음\n",
    ">\n",
    "> 평균 추정에서 bias가 존재하게 됨. 데이터가 커질 수록 상쇄됨\n",
    "\n",
    "3. $1/\\kappa$는 sample size of the prior라고 함. 보통 상수로 택하여, 데이터를 보기 전에 결정함.\n",
    "\n",
    "4. marginal, joint, conditional 전부 normal임\n",
    "\n",
    "> $\\theta$의 분산이 커질수록 ($1/\\kappa$가 작아질수록) prior effect가 줄어든다. 분산이 작아져서 극한에는 한 값만 가지게 되면 prior effect 엄청 커짐"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6080a7b",
   "metadata": {},
   "source": [
    "`-` Normal-normal in mean and variance\n",
    "\n",
    "* Prior를 독립으로 하지 않고, 조건부로 처리\n",
    "\n",
    "$$y | \\theta, \\sigma^2 \\sim N(\\theta, \\sigma^2), ~~ \\theta | \\sigma^2 \\sim N(0, \\kappa \\sigma^2)$$\n",
    "\n",
    "* $p(1/\\sigma^2) \\propto (1/\\sigma^2)^{-1}$ (improper prior)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5becf2b",
   "metadata": {},
   "source": [
    "* Joint distribution of $p(y, \\theta, 1/\\sigma^2)$\n",
    "\n",
    "$$(2\\pi \\sigma^2)^{-\\frac12} \\exp (-0.5(y - \\theta)^2/\\sigma^2)(2\\pi\\kappa\\sigma^2)^{-\\frac12} \\exp(-0.5 \\theta^2 / (\\kappa \\sigma^2))(1/\\sigma^2)^{-\\frac12}$$\n",
    "\n",
    "> 적분했을 때 0이 되는 pdf 형태를 찾아서 나머지를 떼어버리면 됨\n",
    ">\n",
    "> 한두번은 해보길 추천..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c42a87ce",
   "metadata": {},
   "source": [
    "* Posterior of $\\theta$ given $y$.\n",
    "\n",
    "$$p(\\theta | 1/\\sigma^2, y) \\propto N(\\theta, y(1 + 1/\\kappa)^{-1}, (1+1/\\kappa)^{-1}\\sigma^2)$$\n",
    "\n",
    "$$p(1/\\sigma^2 | y) \\propto (1/\\sigma^2)^{\\frac12 - 1}$$\n",
    "\n",
    "> 감마 분포를 따름 (카이제곱 분포로 유도되며, 최종적으로 posterior of $\\theta$ $p(\\theta | y)$는 t분포가 나옴)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79c5d3e9",
   "metadata": {},
   "source": [
    "* Sample이 하나이기 때문에 많은 정보가 없음. 여러 개의 샘플을 확보해야 함 ㅇㅅㅇ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48350b67",
   "metadata": {},
   "source": [
    "`-` $y_i \\sim p(\\cdot | \\theta, \\sigma^2)$\n",
    "\n",
    "* $E[1/\\sigma^2 | y_1, \\cdots, y_n] \\approx {\\hat\\sigma^2}^{\\text{MLE}}$, $\\kappa$가 커질 수록 오차 작아짐\n",
    "* $\\kappa$가 커지면 prior의 분산이 커지게 되므로, non-informative prior에 가까워짐. 이는 MLE와 유사한 결과를 가지게 된다.\n",
    "> 베이지안을 사용해서 MLE와 동일한 결과를 가지게 된다면, 사용할 이유가 있는가? $\\to$ posterior의 분산이 작아지는 성질을 가지고 있기 때문에 이를 활용한다."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

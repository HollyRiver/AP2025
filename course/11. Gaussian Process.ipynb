{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ac2f574f",
   "metadata": {},
   "source": [
    "# Gaussian Process"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "649b2df5",
   "metadata": {},
   "source": [
    "## 1. Gaussian Process"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3eaa335e",
   "metadata": {},
   "source": [
    "* ML에서 가장 성능이 좋\"았\"던 모델\n",
    "* DNN과 관련이 있음"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e508611",
   "metadata": {},
   "source": [
    "`-` Process\n",
    "\n",
    "* 시간에 따라 변화하는 벡터, 공간, 함수\n",
    "* GP: 함수 공간의 random process. random function으로도 불림\n",
    "* 알고 싶은 함수 자체를 알아내는 문제. Prior/Posterior를 함수 자체로 설정\n",
    "\n",
    "> 함수는 각 값들이 연관되어 있음 $\\to$ k차 미분 가능성으로 표시\n",
    ">\n",
    "> 고차원 미분이 가능해질 수록 주변값들과의 연관성이 강해짐\n",
    "\n",
    "* 알아내고자 하는 함수 자체가 최소한 연속은 되는 형태의 함수이다. 모든 포인트가 서로 독립적이면 안됨. correlation이 존재하는 process로 모델링을 해야 함."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f35fc568",
   "metadata": {},
   "source": [
    "`-` Example of a random process\n",
    "\n",
    "* $\\kappa = \\exp \\left(\\frac{-||x-x'||^2}{2t^2}\\right)$\n",
    "* $\\kappa = \\min (x, x')$\n",
    "* $\\kappa = (x^{\\top}x' + c)^2$\n",
    "\n",
    "$\\cdots$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6d11879",
   "metadata": {},
   "source": [
    "`-` Continuous stochastic process (시간을 불가산 무한으로 취급)\n",
    "\n",
    "* 확률은 기본적으로 최소한 가산 무한을 가정해야 함 $\\to$ 불가산 무한을 가산 무한으로 projection.\n",
    "\n",
    "* Notation: $\\mathcal G \\mathcal P (\\boldsymbol \\mu, k)$\n",
    "\n",
    "* For any finite $(x_1, \\cdots, x_N)$ on $\\chi$\n",
    "\n",
    "$$(f(x_1), \\cdots, f(x_N)) \\sim \\mathcal N((\\mu_1, \\cdots, \\mu_N)^{\\top}, \\boldsymbol \\Sigma_N)$$\n",
    "\n",
    "* $\\boldsymbol \\mu$는 mean function. 랜덤하게 만들어지는 값들 중에 평균이 존재한다는 것임.\n",
    "* $\\boldsymbol \\Sigma_N = \\{ k(x_i, x_j) \\}_{(i, j)\\in [N]\\times [N]}$: 커널이 공분산 행렬을 생산함. $\\text{Cov}(x_i, x_j) = k(x_i, x_j)$\n",
    "> process 관점에서 $x_i, x_j$가 가까워질수록 공분산의 절대값은 커져야 한다. 상관성이 강해야 함. (corr의 절대값이 1에 가까워짐)\n",
    ">\n",
    "> $\\mu, k$만 존재하면 된다. $\\mu$는 mean function으로, prior와 비슷하여 $0$으로 설정하면 됨."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d43d8a6a",
   "metadata": {},
   "source": [
    "`-` $k$의 설정\n",
    "\n",
    "* 커널을 통해 공분산을 만들었을 때, 이론적으로 합당해야 함\n",
    "\n",
    "1. Positive semi-definite.\n",
    "\n",
    "$$\\sum_i \\sum_j c_i c_j k(x_i, x_j) \\geq 0 ~ \\text{where} ~ x_i \\in \\chi, c_i \\in \\mathbb R$$\n",
    "\n",
    "2. Consistency\n",
    "\n",
    "$$p(f(x_1)) = \\int p(f(x_1), f(x_2)) df(x_2)$$\n",
    "\n",
    "> 모든 $x_1, x_2$에서 위 수식이 성립해야만 함.\n",
    ">\n",
    "> 이는 GP의 definition에서 유도된다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8e7b404",
   "metadata": {},
   "source": [
    "`-` kernel $k$\n",
    "\n",
    "* Prior의 설정이 잘못되면, likelihood가 들어와도 잘못된 결과가 나올 수 있다.\n",
    "\n",
    "1. $\\boldsymbol K_{ij} = k(x_i, x_j)$는 $f(x_i), f(x_j)$의 공분산이다.\n",
    "2. 다양한 커널이 예측 성질에 차이를 줌\n",
    "3. 다양한 커널 존재"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a17b09fb",
   "metadata": {},
   "source": [
    "## 2. Kernel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "883ef073",
   "metadata": {},
   "source": [
    "`-` Squared Exponential (SE) covariance (RBF kernel)\n",
    "\n",
    "$$k(x, x') = \\sigma^2_0 \\exp \\left( -\\frac{1}{2\\lambda}||x - x'||^2 \\right)$$\n",
    "\n",
    "1.\n",
    "2. $\\sigma_0, \\lambda$는 하이퍼파라미터이다.\n",
    "3. 해당 커널은 매우 부드러움 모양의 함수를 생산"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "198c261f",
   "metadata": {},
   "source": [
    "`-` Matern kernel\n",
    "\n",
    "1. $K_{\\nu}$는 Bessel function으로 결정됨. $\\nu$에 따라서 형태가 많이 달라진다.\n",
    "2. $\\nu = 1/2$일 때, 더 러프한 샘플이 나온다.\n",
    "3. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d47cb637",
   "metadata": {},
   "source": [
    "`-` Non-stationary kernels\n",
    "\n",
    "1. Linear kernel: $k(x, x') = \\sigma^2_0 + x^{\\top}x'$\n",
    "> mean에서 벗어날 수록 매우 달라짐. 변동 심해짐\n",
    "2. Brownian motion: $k(x, x') = \\min(x_1, x_2)$ where $x_1, x_2 \\in \\mathbb R$\n",
    "> Random walk\n",
    "3. Periodic kernel: $k(x, x') = \\exp \\left( - \\frac{2\\lambda \\sin^2((x - x')/2)}{\\lambda^2} \\right)$\n",
    "> 주기성을 고려\n",
    "4. Neural tangent kernel\n",
    "> DNN을 GP로 approximation할 때 사용할 수 있는 일반적인 커널. Gradient를 이용"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "421852f5",
   "metadata": {},
   "source": [
    "`-` Combination of kernel for a new kernel\n",
    "\n",
    "1. Sum: 단순합\n",
    "2. Product: 단순곱\n",
    "3. Convolution: $\\int h(x, z)k(z, z')h(z', x)dzdz'$\n",
    "> Convolution까지는 잘 활용할 필요가 없고, Sum과 Product만으로 충분함"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33a3a58b",
   "metadata": {},
   "source": [
    "## 3. (Bayesian) Prediction with GP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce9118d1",
   "metadata": {},
   "source": [
    "`-` Multivatiate Normal distribution\n",
    "\n",
    "* Normal은 약간 closed distribution임. 결합, 주변, 조건부 전부 정규분포임\n",
    "\n",
    "$$\\boldsymbol y = (\\boldsymbol y_1^{\\top}, \\boldsymbol y_2^{\\top})^{\\top} \\sim \\mathcal N \\left( (\\boldsymbol \\mu_1^{\\top}, \\boldsymbol \\mu_2^{\\top})^{\\top}, \\begin{bmatrix} \\Sigma_{11} & \\Sigma_{12} \\\\ \\Sigma_{21} & \\Sigma_{22} \\end{bmatrix} \\right)$$\n",
    "\n",
    "$$\\boldsymbol y_2 ~|~ \\boldsymbol y_1 \\sim \\mathcal N \\left( \\boldsymbol \\mu_2 + \\Sigma_{21} \\Sigma_{11}^{-1}(\\boldsymbol y_1 - \\boldsymbol \\mu_1) \\right)$$\n",
    "\n",
    "* $f_i$들이 관측되었다고 가정할 때, 관측되지 않은 $f^*$의 분포를 파악할 수 있음. 이와 같은 형태로 Prediction...\n",
    "* $f_i$는 전부 평균만 얘기하기 때문에... 실제로 $\\epsilon$이 들어왔을 때 수식이 좀 바뀜"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4391c8ef",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

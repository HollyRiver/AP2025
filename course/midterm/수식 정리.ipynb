{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "99b89ade",
   "metadata": {},
   "source": [
    "`-` DNN\n",
    "\n",
    "$g_l(\\boldsymbol x) = \\sigma(\\boldsymbol W_l \\boldsymbol x + \\boldsymbol b_l)$, $\\sigma$는 activation function이며, $a(\\cdot) = \\boldsymbol W_a \\cdot + \\boldsymbol b_a$는 scalar function 또는 vector function이라고 할 때\n",
    "\n",
    "$$f(\\boldsymbol x) = a(g_L \\circ g_{L-1} \\circ \\cdots \\circ g_1(\\boldsymbol x))$$\n",
    "\n",
    "> $a$는 최종 netout 벡터를 반환\n",
    "\n",
    "\n",
    "$$\\begin{bmatrix} h_1 \\\\ h_2 \\end{bmatrix} = \\begin{bmatrix} w_{11} & w_{12} \\\\ w_{21} & w_{22} \\end{bmatrix} \\begin{bmatrix} x_1 \\\\ x_2 \\end{bmatrix} + \\begin{bmatrix} b_1 \\\\ b_2 \\end{bmatrix} \\overset{\\sigma}{\\to} \\begin{bmatrix} \\sigma (h_1) \\\\ \\sigma (h_2) \\end{bmatrix}$$\n",
    "\n",
    "> 단순 선형 변환에 비선형 activation function을 추가하여 복잡한 형태를 만들어낸다.\n",
    "\n",
    "* loss function\n",
    "\n",
    "$$l(y, f(\\boldsymbol x~|~\\theta))$$\n",
    "\n",
    "> $l$(손실 측정부) 자체는 convex function이나, $f$(Feature extractor)의 형태가 $\\theta$에 의해 바뀌기 때문에 손실함수는 convex function이 아니다.\n",
    "\n",
    "\n",
    "* Stochastic Gradient Descent\n",
    "\n",
    "$\\mathcal B$를 미니배치라고 할 때,\n",
    "\n",
    "$$\\boldsymbol w_t \\leftarrow w_{t-1} - \\eta_t \\nabla l_{w_{t-1}}(\\mathcal B)$$\n",
    "\n",
    "> 손실함수의 개형을 조금 더 부드럽게 만드는 역할을 수행한다.\n",
    "\n",
    "$$\\sum_{t} \\eta_t = \\infty,~\\sum_{t} \\eta_t^2 < \\infty$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b221a6e",
   "metadata": {},
   "source": [
    "`-` Transfer Learning\n",
    "\n",
    "$g_i: \\mathcal X_s \\to \\mathcal Y_s,~ f: \\mathcal X_t \\to \\mathcal Y_s$(각 도메인에서의 hypothesis)이고, $\\mathcal T, \\mathcal S$는 각각 target, source domain이라고 할 때,\n",
    "\n",
    "$$g_i = w_i \\circ c,~f=v\\circ c$$\n",
    "\n",
    "> $c \\in \\mathcal C,~v \\in \\mathcal V$: common part $c$가 많을 수록, 전이학습의 효과가 커진다. target model은 target data로 $v$만 배우면 된다.\n",
    "\n",
    "* Mathematical frameworks\n",
    "\n",
    "$n, m$을 소스, 타겟 도메인에서의 데이터셋 크기로, $C$는 특정 태스크 수행의 복잡도라고 할 때,\n",
    "\n",
    "$$\\tilde O \\left( \\frac{1}{\\nu} \\sqrt{\\frac{C(\\mathcal C) + tC(\\mathcal V)}{nt}} + \\sqrt{\\frac{C(\\mathcal V)}{m}} \\right)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5edfb0a6",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "`-` Domain Adaptation\n",
    "\n",
    "$p_t, p_s$를 각각 target, source domain의 분포라 하고, $T$를 적절한 변환이라고 할 때,\n",
    "\n",
    "$$\\begin{align}\n",
    "& p_t(x) \\neq p_s(x) \\\\\n",
    "& p_t(T(x)) = p_s(T(x)) \\\\\n",
    "& p_t(y~|~T(x)) = p_s(y~|~T(x))\n",
    "\\end{align}$$\n",
    "\n",
    "> 서로 다른 소스, 타겟 도메인의 분포를 맞춰줄 수 있는 변환을 찾는다.\n",
    ">\n",
    "> 해당 변환을 찾을 수 있다면, 동일한 변환값이 주어졌을 때 label의 조건부 분포가 도메인별로 근접하도록 최대한 맞춘다. 그러면 타겟 도메인의 라벨을 다음과 같이 예측할 수 있다. $p_t(y~|~T(x)=a) ≡ p_s(y~|~T(x) = a)$\n",
    "\n",
    "\n",
    "* Metric Learning (변환된 유클리디안 거리 + 상한/하한 제약조건)\n",
    "\n",
    "$$d_W (x_s^i, x_t^j) = (x_s^i - x_t^j)^{\\top} W (x_s^i - x_t^j)$$\n",
    "\n",
    "> $W$는 $W^{\\frac12}W^{\\frac12}$로 분해될 수 있으므로, 해당 거리는 기존 벡터를 $W^{\\frac12}$로 변환한 $W^{\\frac12}x_s^i$와 $W^{\\frac12}x_t^j$간의 거리라고 생각할 수 있다.\n",
    "\n",
    "\n",
    "$$\\text{arg} \\min_{W ⪰ 0} Tr(W) - \\log \\text{det} (W) ~~ s.t.$$\n",
    "\n",
    "$$d_W (x_s^i, x_t^j) ≤ u ~~~~ \\text{if} ~~ y^i = y^j$$\n",
    "\n",
    "$$d_W (x_s^i, x_t^j) ≥ l ~~~~ \\text{if} ~~ y^i \\neq y^j$$\n",
    "\n",
    "> 레이블이 같을 때, 변환된 거리가 $u$를 넘지 않도록 하며, 레이블이 다를 때, 변환된 거리가 $l$보다 작지 않도록 한다.\n",
    "\n",
    "* Asymmetric Transformations (내적 + 상한/하한 손실함수)\n",
    "\n",
    "$$\\text{sim}_W(x_s^i, x_t^j) = {x_s^i}^{\\top} W x_t^j$$\n",
    "\n",
    "$$L = \\mathbb I (y_s^i = y_t^j) (\\max (0, l - {x_s^i}^{\\top}W x_t^j))^2 + \\mathbb I (y_s^i \\neq y_t^j) (\\max (0, {x_s^i}^{\\top} W x_t^j - u))^2 + \\lambda ||W||_F$$\n",
    "\n",
    "> 변환된 벡터가 같은 방향일수록 유사도가 높음\n",
    ">\n",
    "> 변환 행렬의 값이 너무 커지지 않기 위해 frobenius norm penalty term 부여\n",
    "\n",
    "* Unsupervised DA: MMD (Maximum Mean Discrepancy. 분포간 거리 측정)\n",
    "\n",
    "$$\\text{MMD}(X, Y) = \\sup_{f \\in \\mathcal H,~||f|| ≤ 1} \\mathbb E[f(X)] - \\mathbb E[f(Y)] \\to 0$$\n",
    "\n",
    "> 두 확률 변수의 힐베르트 공간에서의 변환 $f$ 이후, 적률 차이의 상한(maximum mean discrepancy)이 0이면 두 분포는 동일하다.\n",
    "\n",
    "$$⟨\\phi(x),\\phi(y)⟩ = K(x,y)$$\n",
    "\n",
    "> kernel trick에 의하여 고차원 변환의 내적은 커널로 표현할 수 있다.\n",
    "\n",
    "$K(\\cdot, \\cdot)$가 힐베르트 공간에서의 커널일 때, ($K(x, y) = \\exp (-(x-y)^2/\\sigma)$ 같은)\n",
    "\n",
    "$$\\text{MMD}(\\{x_i\\}_{i=1}^n, \\{y_i\\}_{i=1}^m)^2 = \\sum_{i, j} K(x_i, x_j)/n^2 + \\sum_{i, j} K(y_i, y_j)/m^2 - 2\\sum_{i, j} K(x_i, y_j)/mn$$\n",
    "\n",
    "> 전반적으로 $K(x_i, x_j) \\approx K(y_i, y_j) \\approx K(x_i, y_j)$라면 sample MMD는 0에 가까워진다. 즉, Sample MMD를 0으로 줄이도록 최적화하여 두 분포를 같게 만들 수 있다.\n",
    "\n",
    "* Sample reweighting\n",
    "\n",
    "$$\\arg \\min_{\\beta} || \\frac{1}{n} \\sum_{i=1}^n \\beta_i \\phi(x_s^i) - \\frac{1}{m} \\sum_{i=1}^m \\phi(x_t^i)||^2$$\n",
    "\n",
    "$$s.t. ~~ \\beta_i \\in [0, B], ~ i \\in [n], ~ |\\sum_{i=1}^n \\beta_i - n| ≤ n\\epsilon$$\n",
    "\n",
    "> 각 소스 샘플의 중요도를 달리 부여하여 sample MMD를 최소화하고, 이로써 분포를 같게 만듦\n",
    ">\n",
    "> $\\beta_i$들을 거의 0으로 만들어 손실을 줄이는 것을 방지\n",
    "\n",
    "* Sample selection\n",
    "\n",
    "$$\\arg \\min_{\\alpha} || \\frac{1}{\\sum_{i} \\alpha_i} \\sum_{i=1}^n \\alpha \\phi(x_s^i) - \\frac{1}{m}\\sum_{i=1}^m \\phi(x_t^i)||^2$$\n",
    "\n",
    "$$s.t. ~~ \\alpha_i \\in \\{0, 1\\}, ~ i \\in [n], ~ \\frac{1}{\\sum_i \\alpha_i} \\sum_i \\alpha_i y_c^i = \\frac{1}{n} \\sum_i y_c^i$$\n",
    "\n",
    "> Sample reweighting에서의 연속형 가중치 대신, 0과 1로 사용할 소스 샘플 자체를 선택. 선택 후 레이블의 분포 변동으로 인한 결과 왜곡을 방지.\n",
    ">\n",
    "> 타겟 분포와 비슷한 샘플만 선택하여 분포를 동일하게 만듦, 선택 후 레이블의 분포도 유지\n",
    "\n",
    "\n",
    "* Domain Invariant Projection\n",
    "\n",
    "$$\\arg \\max_{W} D_{\\text{MMD}}^2 (W^{\\top}X_s, W^{\\top}X_t)$$\n",
    "\n",
    "$s.t. W^{\\top}W = I$ (orthogonal)\n",
    "\n",
    "> 직교행렬 W로 선형변환 후 MMD를 최소화, 이후 비선형 $\\phi(W^{\\top}X)$로 재변환"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9204c8c",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "`-` Knowledge Distillation\n",
    "\n",
    "* Response-based\n",
    "\n",
    "$$\\sum_{c=0}^C p_s^c \\log \\frac{p_s^c}{p_t^c}$$\n",
    "\n",
    "> KL divergence. 모델이 산출하는 확률값이 유사하도록 조정\n",
    "\n",
    "* Feature-based\n",
    "\n",
    "$$\\tau f / ||f||$$\n",
    "\n",
    "> 모델의 feature가 유사하게 산출되도록 조정. 보통 $f$는 teacher model의 확률벡터 산출 이전의 레이어를 대상으로 하며, 두 모델 간 가중치 스케일을 통일한 뒤 조정\n",
    "\n",
    "* Relation-based\n",
    "\n",
    "> 레이어 간 correlation을 유사하게. 두개 레이어 간 내적이 동일하도록 만듦\n",
    "\n",
    "* Overconfidence: Temperature scale\n",
    "\n",
    "$$\\frac{\\exp (f_i / \\tau)}{\\sum_{i} \\exp (f_i / \\tau)}$$\n",
    "\n",
    "> 보통 한 개의 클래스에 대한 확률만 1에 가까워지고, 나머지는 다 0으로 수렴하는 경우가 많다. Prediction은 잘 수행할 수 있어도, Calibration은 제대로 수행하지 않는다.\n",
    ">\n",
    "> Response-based KD에서 teacher model의 확률 벡터 자체가 잘못되어 있다면, 이를 기반으로 student model을 보정하는 것에 문제가 있다.\n",
    "\n",
    "* Cosine Loss\n",
    "\n",
    "$$\\mathcal L_{\\cos} (x, y) = 1 - \\sigma_{\\cos}(f_{\\theta}(x), \\phi(y))$$\n",
    "\n",
    "> KD에서 weight는 스케일이 균일하지 않다. 따라서 단순 유클리디안 norm보다 방향만을 고려하는 cosine loss를 사용하는 것이 적합하다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "964ff5fb",
   "metadata": {},
   "source": [
    "`-` Bayesian\n",
    "\n",
    "* Bayes Theorem\n",
    "\n",
    "$$\\mathbb P (Z~|~X) = \\frac{\\mathbb P(X~|~Z) \\mathbb P(Z)}{\\mathbb P(X)}$$\n",
    "\n",
    "> unknown quantity $Z$의 확률을 관측된 사건 $X$로 표현\n",
    "\n",
    "\n",
    "* Beta-Bernoulli\n",
    "\n",
    "$$R_i \\sim \\text{Bernoulli}(w),~i \\in [n],~ w \\sim \\text{Beta}(1, 1)$$\n",
    "\n",
    "$$\\begin{align}\n",
    "p(w~|~R_1, R_2, \\cdots, R_n) & \\propto L(w~|~R_1, R_2, \\cdots, R_n) p(w) \\\\\n",
    "& = w^{\\sum_i R_i} (1 - w)^{n - \\sum_i R_i} \\\\\n",
    "& \\propto \\text{Beta}(\\sum_i R_i + 1,~n - \\sum_i R_i + 1) \\\\\n",
    "\n",
    "\\therefore p(r=1~|~R_1, R_2, \\cdots, R_n) & = \\frac{\\sum_i R_i + 1}{n+2}\n",
    "\\end{align}$$\n",
    "\n",
    "> Shirinkage Effect. MLE를 Prior의 평균 방향으로 좁힌 것이 베이지안 추정량이다.\n",
    ">\n",
    "> Data Dominant. 데이터가 충분히 많아진다면 Prior Effect도 줄어든다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a54bd0d",
   "metadata": {},
   "source": [
    "`-` Prior, Model, Posterior\n",
    "\n",
    "* Prior $p(\\theta)$\n",
    "\n",
    "> 파라미터의 분포.\n",
    ">\n",
    "> non-informative prior: $p(\\mu) \\propto 1, p(\\sigma) \\propto 1/\\sigma$. (improper prior)\n",
    ">\n",
    "> 모델이 복잡할수록 prior effect가 커짐\n",
    "\n",
    "* Model or Likelihood $p(y~|~\\theta) = L(\\theta)$\n",
    "\n",
    "$$L(\\theta~|~ \\boldsymbol y) = \\prod_{i=1}^N L(\\theta~|~y_i)$$\n",
    "\n",
    "> Posterior에 데이터가 영향력을 줄 수 있는 통로\n",
    "\n",
    "\n",
    "* Posterior $p(\\theta~|~y)$\n",
    "\n",
    "$$p(\\theta~|~y) = \\frac{p(y~|~\\theta)p(\\theta)}{p(y)} := \\frac{L(\\theta~|~y)p(\\theta)}{p(y)} \\propto L(\\theta~|~y)p(\\theta)$$\n",
    "\n",
    "> 파라미터의 분포.\n",
    ">\n",
    "> Posterior의 support는 Prior의 support보다 클 수 없음\n",
    "\n",
    "* Properties of posterior\n",
    "\n",
    "1. \n",
    "$$p(\\theta~|~y_1, y_2) = \\frac{p(y_2~|~\\theta, y_1)p(\\theta~|~y_1)}{p(y_2~|~y_1)} \\propto p(y_2~|~\\theta, y_1)p(\\theta~|~y_1)$$\n",
    "\n",
    "2. $p(\\theta~|~y) = k(\\theta)h(y) \\to h(y) = 1/\\int k(\\theta)\\theta$\n",
    "\n",
    "$$p(\\theta~|~y) = \\frac{k(\\theta)}{\\int k(\\theta)d\\theta}$$\n",
    "\n",
    "> 데이터가 순차적으로 주어질 경우, 기존 Posterior를 Prior로 취급하여 새로운 Posterior를 계산할 수 있다.\n",
    ">\n",
    "> evidence는 커널을 적분하여 계산할 수 있으므로, Posterior를 아는 데에는 커널로 충분하다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9004d7f6",
   "metadata": {},
   "source": [
    "`-` Posterior Example\n",
    "\n",
    "* Beta-binomial\n",
    "\n",
    "$$y~|~\\theta \\sim \\text{Binom}(n, \\theta),~p(\\theta) ≡\\text{Beta}(\\theta~|~\\alpha, \\beta)$$\n",
    "\n",
    "$$\\mathbb E[\\theta] = \\frac{\\alpha}{\\alpha + \\beta},~\\text{Var} (\\theta) = \\frac{\\alpha \\beta}{(\\alpha + \\beta)^2 (\\alpha + \\beta + 1)}$$\n",
    "\n",
    "$$\\begin{align}\n",
    "p(\\theta~|~y) & \\propto \\theta^y (1-\\theta)^{n-y} \\theta^{\\alpha - 1}(1 - \\theta)^{\\beta - 1} \\\\\n",
    "& = \\theta^{y + \\alpha - 1}(1 - \\theta)^{n-y+\\beta-1} \\\\\n",
    "& \\propto \\text{Beta}(\\theta~|~y + \\alpha, n - y + \\beta)\n",
    "\\end{align}$$\n",
    "\n",
    "> $\\mathbb E [\\theta~|~y] = \\frac{y + \\alpha}{n+\\alpha + \\beta} = \\frac{y}{n}\\times \\frac{n}{n+\\alpha+\\beta} + \\frac{\\alpha}{\\alpha + \\beta} \\times \\frac{\\alpha + \\beta}{n + \\alpha + \\beta}$: Prior의 평균인 $\\frac{\\alpha}{\\alpha + \\beta}$ 방향으로 MLE $\\frac{y}{n}$이 움직인다.\n",
    ">\n",
    "> $\\text{Var}(\\theta~|~y) = \\frac{(y + \\alpha)(n - y + \\beta)}{(n+\\alpha+\\beta)^2(n+\\alpha+\\beta+1)} = O(1/n)$ stochastically.\n",
    ">\n",
    "> n이 커질수록 Prior의 영향력은 줄어들고, Posterior의 분산은 줄어든다.\n",
    "\n",
    "\n",
    "* Normal-normal in mean\n",
    "\n",
    "$$y~|~\\theta \\sim N(\\theta, \\sigma^2),~\\theta \\sim N(0, \\kappa \\sigma^2)$$\n",
    "\n",
    "$$\\begin{align}\n",
    "p(\\theta~|~y) & \\propto \\exp(-0.5(y-\\theta)^2 /\\sigma^2) \\exp(-0.5 (1/\\kappa)\\theta^2/\\sigma^2) \\\\\n",
    "& \\propto \\exp(-0.5(1+1/\\kappa)\\left\\{  \\theta^2 - 2y(1+1/\\kappa)^{-1}\\theta \\right\\} /\\sigma^2) \\\\\n",
    "& \\propto N(\\theta~|~ (1 + 1/\\kappa)^{-1}y,~(1+1/\\kappa)^{-1}\\sigma^2)\n",
    "\\end{align}$$\n",
    "\n",
    "> $\\mathbb E [\\theta~|~\\boldsymbol y] = \\bar y \\times \\frac{n}{n+1/\\kappa} + \\mu_0 \\times \\frac{1/\\kappa}{n+1/\\kappa}$\n",
    ">\n",
    "> $\\text{Var}(\\theta~|~y) = \\frac{\\sigma^2}{n + 1/\\kappa}$\n",
    ">\n",
    "> $1/\\kappa$는 sample size of the prior라고 불리며, 베이지안 추정량은 MLE보다 더 작은 분산을 가진다.\n",
    "\n",
    "\n",
    "* Normal-normal in mean and variance\n",
    "\n",
    "$$y~|~\\theta, \\sigma^2 \\sim N(\\theta, \\sigma^2),~ \\theta~|~\\sigma^2 \\sim N(0, \\kappa \\sigma^2), ~ p(1/\\sigma^2) \\propto (1/\\sigma^2)^{-1}$$\n",
    "\n",
    "$$\\begin{align}\n",
    "p(\\theta~|~1/\\sigma^2, y) & = \\frac{p(y~|~ \\theta, 1/\\sigma^2)p(\\theta~|~1/\\sigma^2)}{p(y~|~1/\\sigma^2)} \\\\\n",
    "& \\propto p(y~|~\\theta, 1/\\sigma^2)p(\\theta~|~1/\\sigma^2) \\\\\n",
    "& \\propto N(\\theta~|~ (1 + 1/\\kappa)^{-1}y,~(1+1/\\kappa)^{-1}\\sigma^2) \\\\ \\\\\n",
    "p(1/\\sigma^2~|~y) & = \\int p(\\theta, 1/\\sigma^2~|y)d\\theta \\\\\n",
    "& \\propto \\int p(\\theta, 1/\\sigma^2, y)d\\theta \\\\\n",
    "& \\propto \\text{Gamma}(1/\\sigma^2 ~|~ 0.5, 0.5 y^2 (1/\\kappa) (1 + 1/\\kappa)^{-1})\n",
    "\\end{align}$$\n",
    "\n",
    "$$\\begin{align}\n",
    "p(\\theta~|~\\sigma^2, y_1, \\cdots, y_n) & ≡ N(\\theta~|~\\bar y \\frac{n}{n + 1/\\kappa}, \\frac{\\sigma^2}{n + 1/\\kappa}) \\\\\n",
    "p(1/\\sigma^2 ~|~y_1, \\cdots, y_n) & ≡ \\text{Gamma}(1/\\sigma^2~|~\\frac{n}{2}, \\frac12 \\sum_{i=1}^n (y_i - \\bar y)^2 + \\frac12 \\frac{\\bar y^2 n/\\kappa}{n + 1/\\kappa})\n",
    "\\end{align}$$\n",
    "\n",
    "> $1/\\kappa$가 작을수록 MLE와의 오차가 줄어들고, Prior Effect가 작아진다. 그리고 분산도 MLE보다 작아진다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9224b034",
   "metadata": {},
   "source": [
    "`-` Exponential Family\n",
    "\n",
    "$\\eta = \\eta(\\theta)$일 때,\n",
    "\n",
    "$$p(y~|~\\theta) = h(y)\\exp (T(y)\\eta - A(\\eta))$$\n",
    "\n",
    "> $T(Y)$는 충분통계량, $\\eta$는 natural parameter. $A(\\eta)$와 $h(y)$는 각각 log partition function, base measure\n",
    "\n",
    "* Properties\n",
    "\n",
    "1. $dA(\\eta)/d\\eta = \\mathbb E [T(y)] := \\mu$ and $d^2 A(\\eta) / d\\eta^2 = \\text{Var}(T(y))$\n",
    "2.\n",
    "\n",
    "$$\\text{KL} (y_1~||~y_2) = \\int \\log \\frac{p_1(s)}{p_2(s)}p_1(s)ds = (\\eta_1 - \\eta_2)\\mu_1 - (A(\\eta_1) - A(\\eta_2))$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29f3ec95",
   "metadata": {},
   "source": [
    "`-` Conjugate Prior\n",
    "\n",
    "모델이 지수족을 따르고, Prior가 $p(\\eta) \\propto \\exp (C \\eta - B(\\eta))$의 형태를 가진다면, Posterior 또한 지수족을 따름이 보장된다.\n",
    "\n",
    "$$\\begin{align}\n",
    "p(\\eta ~ | ~ y) & \\propto p(y ~ | ~ \\eta)p(\\eta) \\\\\n",
    "& \\propto \\exp \\big(T(y)\\eta - A(\\eta)\\big) \\cdot \\exp \\big(C\\eta - B(\\eta) \\big) \\\\\n",
    "& = \\exp \\left[ \\big(C + T(y)\\big)\\eta - \\big(B(\\eta) + A(\\eta)\\big) \\right]\n",
    "\\end{align}$$\n",
    "\n",
    "> Prior의 파라미터를 업데이트하는 것만으로 간단하게 Posterior를 얻을 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b0f7ec4",
   "metadata": {},
   "source": [
    "`-` Monte Carlo Sampling\n",
    "\n",
    "* 같은 확률분포에서 무작위 샘플을 반복적으로 생성하여 원하는 추정량을 수치적으로 근사하는 방법.\n",
    "\n",
    "measurable function $f$에 대하여 $\\mathbb E[f(z)] < \\infty, ~z_i \\overset{i.i.d.}{\\sim}p,~i\\in [n],~n \\to \\infty$일 때,\n",
    "\n",
    "$$\\begin{align}\n",
    "\\mathbb E_n [f(z)] & \\overset{a.s.}{\\to} \\mathbb E [f(z)] \\\\\n",
    "\\sum_{i=1}^n f(z_i)/n & \\overset{a.s.}{\\to} \\int f(z)p(z)dz\n",
    "\\end{align}$$\n",
    "\n",
    "> 경험적 기댓값이 이론적 기댓값으로 수렴한다.\n",
    "\n",
    "* Posterior CDF\n",
    "\n",
    "$z \\overset{i.i.d.}{\\sim} p(z~|~y),~i \\in [n]$라고 할 때,\n",
    "\n",
    "$$\\sum_{i=1}^n \\mathbb I (z_i < c)/n \\to \\int_{\\infty}^c p(z~|~y)dz$$\n",
    "\n",
    "> Posterior에서 c까지의 누적확률을 Monte Carlo Sampling으로 근사할 수 있다. 따라서 Posterior median이나 quantile 등을 직접 근사할 수 있다. (확률이 $q$가 되도록 하는 $c$를 찾으면 됨)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cf56fbd",
   "metadata": {},
   "source": [
    "`-` Importance Sampling\n",
    "\n",
    "* 서로 다른 타겟 분포 $p$와 known distribution $q$에 대하여, $q$에서 샘플링된 데이터를 가중평균하여 타겟 분포에서 샘플링한 것과 동일한 효과를 내도록 만드는 방법\n",
    "\n",
    "known distribution $q$에서 샘플링된 데이터 $z_i \\overset{i.i.d.}{\\sim} q(\\cdot)$와 타겟 분포 $p$에 대하여\n",
    "\n",
    "$$\\sum_{i=1}^n f(z_i)\\frac{p(z_i)}{q(z_i)} q(z_i) /n \\to \\int f(z)\\frac{p(z)}{q(z)}q(z)dz$$\n",
    "\n",
    "> $\\frac{p(z_i)}{q(z_i)} = w_i$로 볼 수 있다.\n",
    "\n",
    "* Properties\n",
    "\n",
    "1. $\\mathbb E_q[w_i f(z_i)] = \\mathbb E_p [f(z_i)]$\n",
    "2. $\\text{Var} (w_i f(z_i)) = \\int \\frac{f(z)^2p(z)^2}{q(z)}dz - \\mathbb E_p [f(z)]^2$\n",
    "3. $\\text{Var} (\\sum_i f(z_i)w_i/n) = \\frac{1}{n}\\sum_i (w_i f(z_i) - \\sum_i w_i f(z_i)/n)^2$\n",
    "4. $q = |f|p/c$라면 minimal variance. MC Samling보다 더 낮은 분산을 가짐."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6287635",
   "metadata": {},
   "source": [
    "`-` Rejection Sampling\n",
    "\n",
    "* $p$의 formula를 알고 있을 때, known distribution $q(x)$로 $p(x)$의 위를 감싸는 envelop $Mq(x), M > 0$를 구성한 뒤 $q$에서 $y$를 샘플링한다. 그 다음 $p(y)/Mq(y)$의 확률로 해당 샘플을 선택하여 $p$에서 샘플링한 것과 동일한 효과를 낸다.\n",
    "\n",
    "1. $y \\sim q, u \\sim U(0, 1),~y ⊥ u$\n",
    "2. if $u < \\frac{p(y)}{Mq(y)} \\to$ accept the sample else reject the sample\n",
    "\n",
    "* Properties\n",
    "\n",
    "1. acceptance rate: $1/M$\n",
    "\n",
    "$$\\mathbb P\\left[ u < \\frac{p(y)}{Mq(y)} \\right] = \\mathbb E \\left[ \\mathbb I \\left( u < \\frac{p(y)}{Mq(y)} \\right) \\right] = \\mathbb E \\mathbb E \\left[ \\mathbb I \\left( u < \\frac{p(y)}{Mq(y)}\\right) ~|~y \\right] \\mathbb E_q \\left[ \\frac{p(y)}{Mq(y)} \\right] = \\frac{1}{M} \\int \\frac{p(y)}{q(y)}q(y)dy = \\frac{1}{M}$$\n",
    "\n",
    "2. 채택된 샘플(rejection samples)은 $p$를 따른다.\n",
    "\n",
    "$$\\begin{align}\n",
    "\\mathbb P\\left[ y ≤ t~|~u < \\frac{p(y)}{Mq(y)} \\right] & = \\mathbb P\\left[ y ≤ t, u < \\frac{p(y)}{Mq(y)} \\right] / \\mathbb P\\left[ u < \\frac{p(y)}{Mq(y)} \\right] \\\\\n",
    "& = \\left( \\int_{y ≤ t} \\frac{p(y)}{Mq(y)}q(y) dy \\right) \\times \\frac{1}{1/M} \\\\\n",
    "& = \\int_{y ≤ t} p(y) dy\n",
    "\\end{align}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d78349ad",
   "metadata": {},
   "source": [
    "`-` Markov chain\n",
    "\n",
    "* 확률변수열 $\\{X_t\\}_{t=0}^{\\infty}, v_i \\in \\mathcal X = \\{1, \\cdots, k\\}$에 대하여 다음을 만족하면, markov chain이다.\n",
    "\n",
    "$$\\mathbb P(X_t = v_t~|~X_{t-1} = v_{t-1}, \\cdots, X_0 = v_0) = \\mathbb P(X_t = v_t~|~X_{t-1} = v_{t-1})$$\n",
    "\n",
    "* $p_{ts}$를 $\\mathbb P(X_{t+1} = s~|~X_t = t)$라고 나타낼 때, transition probability는 다음과 같다.\n",
    "\n",
    "$$\\mathbf P = \\begin{bmatrix} p_{11} & \\cdots & p_{1k} \\\\\n",
    "\\vdots & \\ddots & \\vdots \\\\\n",
    "p_{k1} & \\cdots & p_{kk}\n",
    " \\end{bmatrix}$$\n",
    "\n",
    "> 행별 합은 1이며, 총합은 k이다.\n",
    "\n",
    "$$\\begin{align}\n",
    "\\mathbb P_i (X_n = k) & \\overset{\\text{def}}{=} \\mathbb P(X_n = v_k~|~X_0 = v_i) \\\\\n",
    "T_i^{(r+1)} & \\overset{\\text{def}}{=} \\inf \\{ n ≥ T_i^{(r)}+1~|~X_n = v_i \\}, ~ T_i^{(1)} \\overset{\\text{def}}{=} \\inf\\{ n ≥ 1 ~|~ X_n = v_i \\}\n",
    "\\end{align}$$\n",
    "\n",
    "> $X_0$가 $v_i$로 주어졌을 때 $X_n = v_k$일 확률, $r$번째로 $v_i$를 관측한 시점\n",
    "\n",
    "* Irreducibility\n",
    "\n",
    "모든 연결된 원소들로 이뤄진 집합을 $\\mathcal S$라고 할 때,\n",
    "\n",
    "$$i \\to j: \\mathbb P_i(X_n = j, \\exist n ≥ 0) > 0,~ i, j \\in \\mathcal S$$\n",
    "\n",
    "> 이는 $i ↔ j$에 대해서 성립. 즉, 모든 상태는 연결되어 있어야 한다. 한 상태에서 유한 단계 후 어떤 상태로든 갈 수 있어야 한다.\n",
    "\n",
    "* Recurrency\n",
    "\n",
    "$$\\mathbb P_i(T_i < \\infty) = 1 \\Rightarrow \\sum_{n=0}^{\\infty} \\mathbb P_i (X_n = i) = \\infty$$\n",
    "\n",
    "> 한 상태에서 유한 단계 내에 자신의 상태로 무조건 다시 돌아온다.\n",
    "\n",
    "* Aperiodicity\n",
    "\n",
    "> markov chain이 여러개의 hidden distribution을 가질 수 없다. 이는 주기성이 없어야 함을 의미한다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ad2728d",
   "metadata": {},
   "source": [
    "`-` Stationary Markov Chain\n",
    "\n",
    "markov chain의 초기 분포 $\\lambda$와, stationary distribution $\\pi$와 transition probability matrix $\\mathbf P$에 대하여\n",
    "\n",
    "$$\\lambda^{\\top} \\mathbf P^n \\to \\lambda^{\\top} \\tilde{\\mathbf P} = \\pi^{\\top}$$\n",
    "\n",
    "$$\\pi^{\\top} ≡ \\lambda^{\\top} \\mathbf P^{n+1} = \\lambda^{\\top} \\mathbf P^n \\mathbf P \\to \\pi^{\\top} \\mathbf P \\Rightarrow \\pi^{\\top} = \\pi^{\\top} \\mathbf P$$\n",
    "\n",
    "> 초기값을 어떻게 설정해도 충분한 시간이 지나면 stationary distribution으로 수렴하며, 수렴한 이후에는 체인이 진행되어도 분포가 바뀌지 않는다.\n",
    "\n",
    "* Ergodicity of Markov chain\n",
    "\n",
    "Markov Chain $\\{X_i\\}$이 stationary distribution을 가지고, $n \\to \\infty$일 때, measurable function $f$에 대하여\n",
    "\n",
    "$$\\sum_{i=1}^n f(X_i)/n \\to \\mathbb E_{\\pi} [f(X)] ~ a.e.$$\n",
    "\n",
    "\n",
    "> 일반적인 i.i.d. sample에서의 분산: $Var(\\sum X_i / N) = \\sigma^2/N$\n",
    ">\n",
    "> 정상 분포를 가지는 Markov chain에서의 분산: $Var(\\sum X_i/N) = \\frac{\\sigma^2}{N}(1 + \\delta),~\\delta > 0$\n",
    ">\n",
    "> $\\delta$는 경험적으로 계산 가능하며, 분산이 동등하기 위해서는 $N + \\alpha$ 만큼의 샘플이 필요하다.\n",
    "\n",
    "\n",
    "$$N_{\\text{eff}} = \\frac{N}{1+2\\sum_{t=1}^{\\infty} p_t}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d229ca28",
   "metadata": {},
   "source": [
    "`-` MH algorithm\n",
    "\n",
    "* Continuous Markov chain\n",
    "\n",
    "$$\\mathbb P(X_{t+1} \\in \\mathcal B ~|~ X_t = x, X_{t-1} = \\cdots) = \\int_{\\mathcal B} k(x, y)dy$$\n",
    "\n",
    "$$\\Rightarrow \\int k(x, y)\\pi(x)dx = \\pi(y),~\\int k(y, x)\\pi(y)dx = \\pi(x)$$\n",
    "\n",
    "> stationary distribution 아래에서 전이 전과 후의 확률은 동일\n",
    "\n",
    "* MH algorithm\n",
    "\n",
    "1. 샘플링할 타겟 분포 $\\pi$와 이전 시점의 값 $x$가 주어진다.\n",
    "2. $x$가 주어졌을 때, $y$의 density를 나타내는 커널 $k(x, y)$를 택하고, $X_t = x$가 주어졌을 때 $y$를 샘플링한다.\n",
    "3. acceptance rate $\\alpha_{xy} = \\min\\{1, \\frac{\\pi(y)k(y, x)}{\\pi(x)k(x, y)}\\}$를 계산한다.\n",
    "4. 확률 반영을 위해 독립적으로 $U \\sim U(0, 1)$를 샘플링하고, $U ≤ \\alpha_{xy}$라면 $X_{t+1} = y$로, 아니라면 $X_{t+1} = x$로 택한다. 상기 과정을 반복한다.\n",
    "\n",
    "* selection of $k$\n",
    "\n",
    "> $k(x, y) ≡ N(y~|~x, \\sigma^2)$: $\\pi(y)/\\pi(x)$로 간단하게 acceptance rate를 계산 가능\n",
    ">\n",
    "> $k(x, y) ≡ \\pi(y)$: $\\alpha = 1$로 고정. 이 경우 타겟 분포에서 샘플링하는 것과 동일하므로 효용이 없다.\n",
    "\n",
    "\n",
    "* The detailed balance condition for the MH.\n",
    "\n",
    "$$\\begin{align}\n",
    "\\pi(x)k(x, y) & = \\pi(x) (1-\\alpha_{xy}) \\delta_x (y) + \\pi(x) \\alpha_{xy} h(x, y) \\\\\n",
    "& = \\pi(y)(1-\\alpha_{yx}) \\delta_y (x) + \\pi(y) \\alpha_{yx} h(y, x) \\\\\n",
    "& = \\pi(y)k(y, x)\n",
    "\\end{align}$$\n",
    "\n",
    "> $\\delta_x(y): y = x$일 때만 확률을 가지는 분포\n",
    ">\n",
    "> $\\alpha$의 정의는 detailed balance를 보장하는 형태. detailed balance 조건을 만족하면 stationary condition이 성립"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63f8e309",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

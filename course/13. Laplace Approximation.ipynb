{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "46b82cd8",
   "metadata": {},
   "source": [
    "# Laplace Approximation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d9cc018",
   "metadata": {},
   "source": [
    "## 1. Brief Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a6f98d8",
   "metadata": {},
   "source": [
    "* LA: Variation Inference와 유사하지만, 효율이 더 좋음.\n",
    "\n",
    "* Variation Inference: $p(\\theta~|~y) = \\prod_i p(\\theta_i~|~y)$가 성립하진 않으므로, 조건부 독립인 $\\prod_i q(\\theta)$로 근사\n",
    "* Laplace Approximation: 공분산 행렬의 비대각 원소가 0이 아니여도 됨. Multi-variate Normal Distribution으로 근사"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c672e36d",
   "metadata": {},
   "source": [
    "`-` Taylr Series Expansion\n",
    "\n",
    "$$f(x) \\approx f(x_0) + f'(x_0)(x - x_0) + \\frac{1}{2!}f''(x_0) (x - x_0)^2$$\n",
    "\n",
    "> 모든 차수에서의 미분이 존재해야 성립\n",
    ">\n",
    "> 최소한 $x^* \\in [x, x_0]$는 미분 가능해야...\n",
    "\n",
    "* Starting Point of Laplace approximation: $f(x)$를 2차 선형 함수로 근사하여 표기하겠다.\n",
    "* Uni-model. 최대값이 하나만 존재하는 단봉 형태의 GT라면 Laplace Approximation이 잘 작동할 가능성이 높음."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93129a6d",
   "metadata": {},
   "source": [
    "* MAP Maximum A Priori: Posterior의 Mode를 $\\theta^*$라고 할 때, 이를 정규분포의 $\\mu$와 같이 생각하여 근사\n",
    "* Curvature: 곡률이 커질수록 분산이 작아짐 (sharp shape), 곡률이 작아질수록 분산이 커짐. 곡률로 $\\sigma^2$를 결정. Hessian A\n",
    "\n",
    "> Hessian의 역행렬의 음수를 covariance matrix로 사용. 곡률이 커질수록 분산이 작아지니까... 역수로..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b229ed3",
   "metadata": {},
   "source": [
    "$$\\begin{align}\n",
    "p(\\theta~|~y) & = \\exp( \\log p(\\theta~|~y)) \\\\\n",
    "& \\approx \\exp (\\log p(\\theta^*)) ...\n",
    "\\end{align}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a79e030c",
   "metadata": {},
   "source": [
    "> 공분산 행렬이 diagnal matrix가 아니기 때문에, 독립이 아닌 정규분포로 근사할 수 있음.\n",
    ">\n",
    "> 차원이 작을 경우에만 할 수 있음."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b388a7d4",
   "metadata": {},
   "source": [
    "`-` BIC와 Evidence\n",
    "\n",
    "$$\\int p(y~|~\\theta) p(\\theta) d\\theta$$\n",
    "\n",
    "> 값이 클수록 좋음... 이 값을 키우기 위해 모형과 Prior를 잘 설정해야 함.\n",
    "\n",
    "$$-2 \\log p(y) \\approx - 2 \\log p(y~|~\\theta^*) + p \\log n$$\n",
    "\n",
    "> AIC와 달리 뒤쪽 term의 비중이 더 커짐. 데이터가 커질수록 모델 파라미터를 줄여야 한다. (뒤쪽 p는 그거임) Overfitting의 우려는 매우 줄어드나, 약간 Underfitting할 우려가 있음.\n",
    ">\n",
    "> BIC가 작을수록 Evidence가 큰 것과 비슷함.\n",
    "\n",
    "따라서 Overfitting이 걱정된다면 베이지안 방법을 사용하라."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baa196a3",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

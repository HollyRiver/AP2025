{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5d633217",
   "metadata": {},
   "source": [
    "## Foundation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "381dd13d",
   "metadata": {},
   "source": [
    "* $(y, \\theta) \\to (y, z). ~~ p(y~|~z), ~ p(z)$\n",
    "\n",
    "> $\\theta$의 차원이 매우 커지면, 다변량에서의 샘플링은 굉장히 어려움. 다변량 posterior sampling $\\to$ Gipps sampling. $\\theta_1^* \\sim p(\\theta_1 ~ | ~ \\theta_2, \\theta_3, ..., y)$\n",
    ">\n",
    "> $(\\theta_1^*, \\theta_2^*, ...)$이러한 일변량 샘플링으로 바꿈. $d$가 커지면 샘플링 많이 해야함. 사실상 다변량에서 샘플링은 어렵다!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5756fcd",
   "metadata": {},
   "source": [
    "`-` Naive Bayes와 비슷\n",
    "\n",
    "* 복잡한 문제를 간단한 문제로 바꿔버림\n",
    "\n",
    "$$p(\\theta_1, ..., \\theta_d ~ | ~ y) \\approx q_{\\phi_1}(\\theta_1)q_{\\phi_2}(\\theta_2) \\cdots q_{\\phi_d}(\\theta_d)$$\n",
    "\n",
    "> $q$는 대충 정규분포\n",
    ">\n",
    "> 다 독립인 것으로 치고, posterior를 근사하자. 이러면 샘플링이 매우 쉬움. 그냥 각각 샘플링하면 됨.\n",
    "\n",
    "* 두 분포가 가까운 정도는 $KL(q_{\\phi}(\\theta)~|~p(\\theta~|~y))$로 근사"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e637ebff",
   "metadata": {},
   "source": [
    "`-` ELBO\n",
    "\n",
    "$$\\begin{align}\n",
    "p(y) & = \\int p(y, z)dz \\\\\n",
    "& = \\int p(y~|~z)p(z)dz\n",
    "\\end{align}$$\n",
    "\n",
    "$$\\begin{align}\n",
    "p(y_0) & = \\int p(y_0, z)dz \\\\\n",
    "& = \\int p(y_0~|~z)p(z)dz\n",
    "\\end{align}$$\n",
    "\n",
    "> $y_0$가 관측이 되었을 때, 관측된 값의 확률을 낮게 만들면 이상한 것임\n",
    "\n",
    "* Posterior와 Prior를 설정했을 때, 관측된 데이터를 가장 잘 설명하도록.\n",
    "* 관측된 데이터를 $p$가 잘 설명하고 있다면, $p(y_0)$가 높아질 것. evidence의 관점\n",
    "> 설정한 확률 모형이 내가 관측한 데이터를 얼마나 잘 설명하고 있는가?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b81feebb",
   "metadata": {},
   "source": [
    "$$\\mathbb E [X^2] ≥ \\mathbb E[X]^2 ~ \\to \\mathbb E [g(X)] ≥ \\mathbb g(E(X))$$\n",
    "\n",
    "> $g(\\cdot)$는 convex function. concave라면 부호 뒤바뀜.\n",
    "\n",
    "$$\\begin{align}\n",
    "\\log p(y) & = \\log \\int p(y, z)dz \\\\\n",
    "& = \\log \\int \\frac{p(y, z)}{q(z)}q(z)dz \\\\\n",
    "& ≥ \\int \\log \\frac{p(y, z)}{q(z)}q(z)dz \\\\\n",
    "\\therefore \\log p(y) & ≥ \\int \\log \\frac{p(y, z)}{q(z)}q(z)dz \\\\\n",
    "\\int \\log p(y) q(z)dz & ≥ \\int \\log \\frac{p(y, z)}{q(z)}q(z)dz \\\\\n",
    "\\Rightarrow & \\int \\log p(y)q(z) - \\log \\frac{p(y, z)}{q(z)}q(z)dz ≥ 0 \\\\\n",
    "\\end{align}$$\n",
    "\n",
    "> 두 값이 가까워지면 KL divergence가 줄어듦.\n",
    ">\n",
    "> 하한 ELBO를 optimization하면 됨. $q$의 적당한 평균과 분산을 선택해서, ELBO를 계속 키운다. $\\log p(y)$의 하한을 키움.\n",
    ">\n",
    "> $q$는 plexible하지 않으므로, 완벽하게 $\\log p(y)$과 동일할 수는 없음."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f93c23e7",
   "metadata": {},
   "source": [
    "`-` ELBO\n",
    "\n",
    "$$\\int \\log \\frac{p(y, z)}{q(z)} q(z)dz = \\int \\log \\frac{p(y~|~z)p(z)}{q(z)} q(z)dz = \\int \\log p(y, z)dz + \\int \\log p(z)dz$$\n",
    "\n",
    "> $q$에 대한 파라미터 $\\phi$와, $\\theta$를 최적화.\n",
    ">\n",
    "> 뒤쪽은 KL divergence term으로, penalty로 적용됨\n",
    "\n",
    "* 하한을 maximization하면, posterior와 근사되는 q와 거리가 가까워진다.\n",
    "* 하한은 likelihood와 penalty로 나뉜다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67123b74",
   "metadata": {},
   "source": [
    "* $P_{\\theta}(y~|~z)$에 아는 분포를 넣어보고, 기댓값을 손으로 열심히 계산: 전통적인 variation bayes\n",
    "* DNN으로 계산"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b674664",
   "metadata": {},
   "source": [
    "## Variational Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "215665aa",
   "metadata": {},
   "source": [
    "$$p(\\theta~|~y) = \\frac{p(y~|~\\theta)p(\\theta)}{p(y)}$$\n",
    "\n",
    "> Posterior를 얻은 다음, 그 분포를 다 가져다 쓰기는 힘드니까... 평균/median/quantile 등의 quantity로만 가지고 있는 경우가 많음. Bayesian Estimator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5216cbea",
   "metadata": {},
   "source": [
    "* Classification: 확률값을 산출. 예측의 관점에선 critical value만 넘으면 똑같은 결과를 산출함\n",
    "> 확률값이 유사한 경우, 결과를 믿기 어려움. 확률값에 의미가 있음. $\\to$ 사람이 경계해야 할 요소를 만들어낼 수 있음\n",
    ">\n",
    "> Overconfidence: 한 분류에 과한 확률을 책정. 해당 분류 문제의 난이도를 판단하기 어려움."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "321fabcf",
   "metadata": {},
   "source": [
    "`-` Non-Conjugate (DNN)를 위한\n",
    "\n",
    "* Sampling을 사용\n",
    "* i.i.d.가 아닌 경우에 Markov Chain을 사용 $\\to$ quantity 획득.\n",
    "> MH algorithm: 자기 자신의 상태로 돌아올 확률을 전이할 확률과 결합\n",
    "\n",
    "\n",
    "`-` 파라미터 $\\theta$의 차원?\n",
    "\n",
    "* 모수 $\\theta$의 차원이 굉장히 커짐. 다차원 샘플링의 난이도는 지수적으로 증가\n",
    "* 공간과 시간 부족으로 인해 강의노트에 안넣음.\n",
    "> Gipps Sampling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93954487",
   "metadata": {},
   "source": [
    "`-` Gipps Sampling\n",
    "\n",
    "* 분포가 $p(x, y)$를 따르는 샘플링을 하고 싶다.\n",
    "> 한 번에 샘플링하려면 그냥 하면 됨: $(x, y) \\sim p(x, y)$ 그냥 할 수 있나? 모르겠음.\n",
    ">\n",
    "> 나눠서 하나씩 샘플링한 후 $(x, y)$를 구성하는 방법\n",
    "\n",
    "* $x \\sim p(x)$를 샘플링 후, $y \\sim p(y~|~x)$를 샘플링해야 함.\n",
    "> 파라미터 차원이 커질 경우, 계속 변하는 복잡한 조건부 확률분포에서의 샘플링을 연속해야 함.\n",
    "\n",
    "$$p(x, y, z) = p(x)p(y~|~x)p(z~|~x, y)$$\n",
    "\n",
    "\n",
    "* Gipps Sampling\n",
    "\n",
    "1. $x^* \\sim p(x~|~y)$\n",
    "2. $y^* \\sim p(y~|~x^*)$\n",
    "\n",
    "> 자기자신을 제외하고 나머지 변수들을 모두 조건부 변수로 넘김.\n",
    ">\n",
    "> $p$, 분포를 하나만 알면 해당 분포를 계속해서 사용할 수 있음. Cyclic\n",
    ">\n",
    "> $(x^{(0)}, y^{(0)}) \\to (x^{(1)}, y^{(1)}) \\to \\cdots \\to (x^{(n)}, y^{(n)})$. 일종의 markov chain이라고 이해할 수 있음.\n",
    ">\n",
    "> 처음에 $p(x, y)$에서 시작해서, 계속 분포가 바뀜. 전이됨. -> MH 알고리즘의 특별한 형태"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ea78f18",
   "metadata": {},
   "source": [
    "$$(x, y) \\to (x, y^*) \\to (x^*, y^*)$$\n",
    "\n",
    "> MH 알고리즘의 $\\pi$와 커널을 이용할 수 있음."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15f63f03",
   "metadata": {},
   "source": [
    "$$\\begin{align}\n",
    "(x, y) \\to (x, y^*)&:~p(x, y)p(y^*~|~x) = \\pi(x)k(x, y) \\\\\n",
    "(x, y^*) \\to (x, y)&:~p(x, y^*)p(y~|~x) = \\pi(y)k(y, x) \\\\\n",
    "& \\Rightarrow \\frac{p(x, y)}{p(y~|~x)}\\frac{p(y^*~|~x)}{p(x, y^*)}\n",
    "\\end{align}$$\n",
    "\n",
    "> 무조건 accept하는, 무조건 분포가 이동하는 MH algorithm.\n",
    ">\n",
    "> 나머지 고정, 하나를 움직임을 반복 (coordinate wise) $\\to$ 원하는 분포를 따르는 stationary distribution로 이동."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c590c1ce",
   "metadata": {},
   "source": [
    "`-` Variational Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3ed86b3",
   "metadata": {},
   "source": [
    "* $x_{1:m}$까지 주어지는 값, $z$를 변수.\n",
    "\n",
    "$$\\begin{align}\n",
    "\\mathcal L & = p(x_{1:n}, z_{1:m}) \\\\\n",
    "& = p(x_{1:n}) \\prod_{i=1}^m p(x_i ~|~z_{1:(i-1)}, x_{1:n})\n",
    "\\end{align}$$\n",
    "\n",
    "> 일반적으로 이렇게 사용함. $z_1,~z_2|z_1,~(z_3|z_2, z_2), ...$\n",
    ">\n",
    "> 하지만 이걸 안쓰고, 다 given시킨다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49cabd30",
   "metadata": {},
   "source": [
    "`-` VB and mean-field approximation\n",
    "\n",
    "$$\\begin{align}\n",
    "\\log p(y)& ≥ \\text{ELBO} \\\\\n",
    "\\log p(y) - \\text{ELBO} & = \\text{KL}(q~||~p)\n",
    "\\end{align}$$\n",
    "\n",
    "* negative ELBO\n",
    "\n",
    "$$\\begin{align}\n",
    "\\mathcal L & = - \\mathbb E_q \\left[ \\log \\frac{\\prod_{i=1}^m q_i(z_i)}{p(z_{1:m}, x_{1:n})} \\right] \\\\\n",
    "& = \\int q_j(z_j) \\int \\prod_{k\\neq j} q_k(z_k) \\log p(z_{1:m}, y_{1:n})dz_{-j}dz_j - \\int q_j(z_j) \\int \\prod_{k\\neq j}q_k(z_k) \\sum_{k=1}^m \\log q_k(z_k)dz_{-j}dz_j \\\\\n",
    "\\end{align}$$\n",
    "\n",
    "> ELBO의 $q$는 각 파라미터 $z_i$에 대한 함수의 곱으로 표현(독립 가정)\n",
    ">\n",
    "> $m$개의 $q_i$를 이용해서 최적화를 수행해야 함.\n",
    "\n",
    "Let $\\mathbb E_{-j} [\\log p(z_{1:m}, y_{1:n})] = \\int \\prod_{k \\neq j}q_k(z_k) \\log p(z_{q:m}, y_{1:n})dz_{-j}$\n",
    "\n",
    "$$\\begin{align}\n",
    "\\mathcal L & = \\int q_j(z_j) \\mathbb E_{-j} [\\log p(z_{1:m}, y_{1:n})] dz_j - \\int q_j(z_j) \\log q_j(z_j) dz_j - \\int \\prod_{k \\neq j} q_k(z_k) \\sum_{k \\neq j} \\log q_k(z_k) dz_{-j} \\\\\n",
    "& = \\int q_j(z_j) \\mathbb E_{-j} [\\log p(z_{1:m}, y_{1:n})] dz_j - \\int q_j(z_j) \\log q_j(z_j) dz_j + C\n",
    "\\end{align}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b346144",
   "metadata": {},
   "source": [
    "`-` 함수에 대한 미분: q를 이용해서 손실을 최적화\n",
    "\n",
    "* $f(x)$: 도메인을 벡터의 원소로 이해하고, 산출되는 값만 취하면 되니까. 함수를 벡터로 이해\n",
    "> $q + \\epsilon v$. 변화량 $v$를 함수 $q$와 같은 공간에서 정의되는 $\\phi$로 설정.\n",
    ">\n",
    "> $\\lim_{\\epsilon \\to 0} \\frac{\\mathcal L(q + \\epsilon \\phi) - \\mathcal L (q)}{\\epsilon}$: $\\phi$가 어떤 함수인지에 따라 값이 바뀜. $\\dot q_{\\mathcal L}[\\phi] = 0$. $\\phi$의 방향으로 갈 때, 극점.\n",
    ">\n",
    "> $\\mathcal L$이 최소가 되는 $q$를 찾기 위해선 모든 $\\phi$에 대해서 $\\dot q_{\\mathcal L}[\\phi]=0$이 성립되어야 한다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8abfd382",
   "metadata": {},
   "source": [
    "* Gibbs and constraint of $\\int q_j(z_j)dz_j = 1$\n",
    "\n",
    "* funtional derivtive $\\partial \\mathcal L_j/\\partial q_j(z_j)$\n",
    "\n",
    "$$\\int \\phi \\{ \\mathcal E_{-j} [\\log p(z_{1:m}, x_{1:n})] - (\\log q(z_j) + 1) \\} dz_j = 0$$\n",
    "\n",
    "> result: $q_j(z_j) \\propto \\exp(\\mathbb E_{-j}[\\log p(z_{1:m}, x_{1:n})])$. 어떤 분포로 설정하든, 이용 가능한 일반화된 경우\n",
    ">\n",
    "> Gibbs sampling처럼 한 개의 파라미터씩 최적화해나가겠다. 함수 $q$ 자체를 알아내겠다. 가장 일반화된 이론.\n",
    ">\n",
    "> Expectation이 존재하므로, 적분의 개념이 무조건 필요함. 적분이 가능한 경우에만 계산할 수 있음."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f25d8ba1",
   "metadata": {},
   "source": [
    "`-` 계산...\n",
    "\n",
    "* 사람이 손으로 계산해야 함. 한 개의 변수씩 기댓값을 취하면서 $q$ 분포 뽑아냄...\n",
    "* 어떻게든 손으로 계산할 수 있음. 손으로 계산할 수 있는 매우 훌륭한 도구.\n",
    "* bigdata에서도 잘 적용됨.\n",
    "* 분포의 평균은 잘 추정할 수 있으나, 분산은 잘 하지 못한다는 치명적인 단점. mean을 알면 좋긴 하니까...\n",
    "* $p(x~|~z)$의 closed form이 존재하지 않은 경우, 파라미터 추정에 네트워크를 이용하는 등의 경우 계산이 불가능하거나 매우 어려움. 분포 자체가 매우 복잡하면 어려움. $\\to$ AutoEncoder가 도입됨."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2d8a788",
   "metadata": {},
   "source": [
    "### Example"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaab4b55",
   "metadata": {},
   "source": [
    "`-` Normal-Gamma priors $(\\mu, \\tau) ≡ z_{1:2}$. $1/\\sigma^2 = \\tau$라고 그냥 편히 계산할 수 있도록 만들자. 분포 이해하기 편해짐\n",
    "\n",
    "$$\\begin{align}\n",
    "y_i~|~\\mu, \\tau & \\sim \\mathcal N(\\mu, \\tau^{-1}),~i \\in [N], \\\\\n",
    "\\mu & \\sim \\mathcal N(\\mu_0, (\\kappa_0 \\tau)^{-1}), \\\\\n",
    "\\tau & \\sim\n",
    "\\end{align}$$\n",
    "\n",
    "* $\\tau$가 작으면 $\\sigma^2$가 큼 <-> $\\tau$가 크면 $\\sigma^2$가 작음.\n",
    "> precition이라 명명. $\\tau$가 클수록 $\\mu$의 범위가 한정되어 정밀도가 높다고 말할 수 있음.\n",
    "\n",
    "* Joint distribution: 모든 값들은 Joint distribution에서 도출됨\n",
    "\n",
    "$$\\log p(\\boldsymbol x, \\mu, \\tau) = \\frac{N}{2} \\log \\tau - \\frac{\\tau}{2} \\sum_{i=1}^N ()$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b1503ac",
   "metadata": {},
   "source": [
    "* The first approximation for $\\mu$.\n",
    "\n",
    "$$\\begin{align}\n",
    "\\log q_{\\mu}(\\mu) = \\mathbb E_{\\tau} [\\log p(x, \\mu, \\tau)] + C_0\n",
    "\\end{align}$$\n",
    "\n",
    "> $\\boldsymbol x$는 스칼라 취급\n",
    ">\n",
    "> $\\mu$가 given일 때 $\\tau$, $\\tau$가 given일 때 $\\mu$\n",
    ">\n",
    "> 아무튼 잘 나옵니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a06d933a",
   "metadata": {},
   "source": [
    "$$\\sum_{i=1}^N (y_i - \\mu)^2 ≥ \\sum_{i=1}^N (y_i - \\bar y)^2$$\n",
    "\n",
    "$$\\begin{align}\n",
    "\\sum (y_i - \\mu)^2 & = \\sum (y_i - \\bar y + \\bar y - \\mu)^2 \\\\\n",
    "& = \\sum (y_i - \\bar y)^2 + n (\\bar y - \\mu)^2 \\\\\n",
    "& ≥ \\sum (y_i - \\bar y)^2\n",
    "\\end{align}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db593048",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

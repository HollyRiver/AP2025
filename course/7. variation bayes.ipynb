{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "381dd13d",
   "metadata": {},
   "source": [
    "* $(y, \\theta) \\to (y, z). ~~ p(y~|~z), ~ p(z)$\n",
    "\n",
    "> $\\theta$의 차원이 매우 커지면, 다변량에서의 샘플링은 굉장히 어려움. 다변량 posterior sampling $\\to$ Gip sampling. $\\theta_1^* \\sim p(\\theta_1 ~ | ~ \\theta_2, \\theta_3, ..., y)$\n",
    ">\n",
    "> $(\\theta_1^*, \\theta_2^*, ...)$이러한 일변량 샘플링으로 바꿈. $d$가 커지면 샘플링 많이 해야함. 사실상 다변량에서 샘플링은 어렵다!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5756fcd",
   "metadata": {},
   "source": [
    "`-` Naive Bayes와 비슷\n",
    "\n",
    "* 복잡한 문제를 간단한 문제로 바꿔버림\n",
    "\n",
    "$$p(\\theta_1, ..., \\theta_d ~ | ~ y) \\approx q_{\\phi_1}(\\theta_1)q_{\\phi_2}(\\theta_2) \\cdots q_{\\phi_d}(\\theta_d)$$\n",
    "\n",
    "> $q$는 대충 정규분포\n",
    ">\n",
    "> 다 독립인 것으로 치고, posterior를 근사하자. 이러면 샘플링이 매우 쉬움. 그냥 각각 샘플링하면 됨.\n",
    "\n",
    "* 두 분포가 가까운 정도는 $KL(q_{\\phi}(\\theta)~|~p(\\theta~|~y))$로 근사"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e637ebff",
   "metadata": {},
   "source": [
    "`-` ELBO\n",
    "\n",
    "$$\\begin{align}\n",
    "p(y) & = \\int p(y, z)dz \\\\\n",
    "& = \\int p(y~|~z)p(z)dz\n",
    "\\end{align}$$\n",
    "\n",
    "$$\\begin{align}\n",
    "p(y_0) & = \\int p(y_0, z)dz \\\\\n",
    "& = \\int p(y_0~|~z)p(z)dz\n",
    "\\end{align}$$\n",
    "\n",
    "> $y_0$가 관측이 되었을 때, 관측된 값의 확률을 낮게 만들면 이상한 것임\n",
    "\n",
    "* Posterior와 Prior를 설정했을 때, 관측된 데이터를 가장 잘 설명하도록.\n",
    "* 관측된 데이터를 $p$가 잘 설명하고 있다면, $p(y_0)$가 높아질 것. evidence의 관점\n",
    "> 설정한 확률 모형이 내가 관측한 데이터를 얼마나 잘 설명하고 있는가?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b81feebb",
   "metadata": {},
   "source": [
    "$$\\mathbb E [X^2] ≥ \\mathbb E[X]^2 ~ \\to \\mathbb E [g(X)] ≥ \\mathbb g(E(X))$$\n",
    "\n",
    "> $g(\\cdot)$는 convex function. concave라면 부호 뒤바뀜.\n",
    "\n",
    "$$\\begin{align}\n",
    "\\log p(y) & = \\log \\int p(y, z)dz \\\\\n",
    "& = \\log \\int \\frac{p(y, z)}{q(z)}q(z)dz \\\\\n",
    "& ≥ \\int \\log \\frac{p(y, z)}{q(z)}q(z)dz \\\\\n",
    "\\therefore \\log p(y) & ≥ \\int \\log \\frac{p(y, z)}{q(z)}q(z)dz \\\\\n",
    "\\int \\log p(y) q(z)dz & ≥ \\int \\log \\frac{p(y, z)}{q(z)}q(z)dz \\\\\n",
    "\\Rightarrow & \\int \\log p(y)q(z) - \\log \\frac{p(y, z)}{q(z)}q(z)dz ≥ 0 \\\\\n",
    "\\end{align}$$\n",
    "\n",
    "> 두 값이 가까워지면 KL divergence가 줄어듦.\n",
    ">\n",
    "> 하한 ELBO를 optimization하면 됨. $q$의 적당한 평균과 분산을 선택해서, ELBO를 계속 키운다. $\\log p(y)$의 하한을 키움.\n",
    ">\n",
    "> $q$는 plexible하지 않으므로, 완벽하게 $\\log p(y)$과 동일할 수는 없음."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f93c23e7",
   "metadata": {},
   "source": [
    "`-` ELBO\n",
    "\n",
    "$$\\int \\log \\frac{p(y, z)}{q(z)} q(z)dz = \\int \\log \\frac{p(y~|~z)p(z)}{q(z)} q(z)dz = \\int \\log p(y, z)dz + \\int \\log p(z)dz$$\n",
    "\n",
    "> $q$에 대한 파라미터 $\\phi$와, $\\theta$를 최적화.\n",
    ">\n",
    "> 뒤쪽은 KL divergence term으로, penalty로 적용됨\n",
    "\n",
    "* 하한을 maximization하면, posterior와 근사되는 q와 거리가 가까워진다.\n",
    "* 하한은 likelihood와 penalty로 나뉜다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67123b74",
   "metadata": {},
   "source": [
    "* $P_{\\theta}(y~|~z)$에 아는 분포를 넣어보고, 기댓값을 손으로 열심히 계산: 전통적인 variation bayes\n",
    "* DNN으로 계산"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b674664",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

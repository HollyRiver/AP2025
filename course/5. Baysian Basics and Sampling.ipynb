{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4f4584f2",
   "metadata": {},
   "source": [
    "# 5. Baysian Basics and Sampling (2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96632d96",
   "metadata": {},
   "source": [
    "## 1. Intro. to Bayesian Sampling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "333fa043",
   "metadata": {},
   "source": [
    "* Posterior는 분포이다.\n",
    "\n",
    "$(\\Omega, F, P)$에서 $\\Omega \\overset{X}{\\to} \\mathbb{R}, ~ X \\sim F (\\text{cdf})$. cdf를 설명하기 위해 pdf가 나온 것이며, 이는 개별 지점에서의 확률과 연관되어 있음.\n",
    "\n",
    "* explicit formula가 있으면, 계산 쉬움... 하지만 없으면, 수식으로 정리가 잘 안되고, 수치적으로도 계산이 어려울 경우 sampling approache가 필요함."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0380d0fc",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "`-` Sampling?\n",
    "\n",
    "* $z_i \\sim h, i \\in [n]$. i.i.d sample을 가정할 때, pdf $h$를 산출\n",
    "* random variable $z$와 $\\boldsymbol z = (z_1, \\cdots, z_k)$를 고려\n",
    "* $z_i$는 iid임을 이용할 수도 있고, Markov chain $z_t, ~ t = 0, 1, ...$을 이용할 수도 있음.\n",
    "> Chain을 이용해서 어떤 분포를 근사시키는 방법으로 문제 풀이. Chain의 joint dist를 결정하는 $(\\lambda, p)$를 이용하여 $\\pi$를 계산... $\\pi$를 정해놓고, $\\pi$를 stationary distribution을 가지는 $\\lambda, p$를 찾는 문제가 됨"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a0dccc6",
   "metadata": {},
   "source": [
    "## 2. Monte Carlo Sampling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66db1e6b",
   "metadata": {},
   "source": [
    "$$\\sum_{i=1}^n f(z_i) / n \\overset{\\text{a.s.}}{\\to} ~ \\mathbb E[f(z)] ~ \\text{as} ~ n \\to \\infty ~ \\text{where} ~ \\mathbb E [f(z)] < \\infty$$\n",
    "\n",
    "> strong LRT. $z_i$들은 iid."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d74328ff",
   "metadata": {},
   "source": [
    "`-` General Formulation\n",
    "\n",
    "$$\\begin{align}\n",
    "\\mathbb E_n[f(z)] & \\overset{\\text{a.s.}}{\\to} \\mathbb E [f(z)] \\\\\n",
    "\\sum_{i=1}^n f(z_i)/n & \\overset{\\text{a.s.}}{\\to} \\int f(z)p(z)dz\n",
    "\\end{align}$$\n",
    "\n",
    "as $n \\to \\infty$\n",
    "\n",
    "* measurable function $f$에 대해서 모두 성립"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdd6b3db",
   "metadata": {},
   "source": [
    "`-` Example\n",
    "\n",
    "* $r_i \\overset{i.i.d.}{\\sim} U(0, 1)^2$. $R$은 부분 원의 영역이라고 하면...\n",
    "\n",
    "$$\\sum_{i=1}^n \\mathbb I (r_i \\in R)/n \\to \\int_{[0, 1]^2} \\mathbb I (r \\in R) dr = \\frac{\\pi}{4}$$\n",
    "\n",
    "a.e. as $n \\to \\infty$\n",
    "\n",
    "* $\\sum_{i=1}^n I(z_i < c)/n \\to \\int_{-\\infty}^c p(z ~ | ~ y)dz$. 샘플링을 통해 확률을 추정할 수 있음.\n",
    "\n",
    "* 참고: inverse-cdf. $F^{-1}(u), ~ U \\sim U(0, 1)$에서 확률분포 추출함"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a2a6e6d",
   "metadata": {},
   "source": [
    "## 3. Importance Sampling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b68081a5",
   "metadata": {},
   "source": [
    "서로 다른 분포 f, g에 대해서 f에서 샘플링된 데이터를 가중평균\n",
    "\n",
    "* $z_i \\overset{i.i.d.}{\\sim} q(\\cdot)$, target $p$에 대해서...\n",
    "\n",
    "$$\\sum f(z_i) \\frac{p(z_i)}{q(z_i)}/n \\to \\int f(z) \\frac{p(z)}{q(z)}q(z)dz = \\int f(z)p(z)dz$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44c30347",
   "metadata": {},
   "source": [
    "`-` Properties\n",
    "\n",
    "* $w_i f(z_i)$의 평균은 $E_p[f(z)]$\n",
    "* 만약 $q = |f|p/c$라면, minimal variance를 만들 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "129a7a94",
   "metadata": {},
   "source": [
    "## 4. Rejection Sampling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63c5b91a",
   "metadata": {},
   "source": [
    "formula $p$는 알고 있으나, sampling이 어려울 때. $p(x)$를 감싸는 단순한 개형의 envelop $M q(x)$를 고려\n",
    "\n",
    "* $p(x) ≤ Mq(x), ~ x \\in X$\n",
    "\n",
    "> $q(x)$에서 샘플링하고, $p(x)$보다 큰 값을 가지는 샘플은 rejection\n",
    "\n",
    "1. $u \\sim U(0, 1), u ⊥ y$에 대해서, $u < \\frac{p(y)}{Mq(y)}$를 만족하는지를 확인\n",
    "2. 만족한다면, 샘플을 택하고, 만족하지 않는다면, 샘플을 reject.\n",
    "\n",
    "> 너무 많은 것들을 버리게 한다면, rejection rate가 높다면 효율성이 떨어짐...\n",
    ">\n",
    "> Importance Sampling은 모든 샘플을 전부 활용하지만, 얘는 버림. 효율성의 문제"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9893bb69",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "`-` Properties\n",
    "\n",
    "1. acceptance rate $1/M$\n",
    "2. 아무튼 잘 나옴 ㅇㅇ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4aea2373",
   "metadata": {},
   "source": [
    "## 5. Markov chain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6e1798a",
   "metadata": {},
   "source": [
    "Discrete sequence of random variables $\\{X_t\\}_{t=0}^{\\infty}$\n",
    "\n",
    "* $P(X_0, X_1, X_2) = P(X_0)P(X_1 ~ | ~ X_0)P(X_2 ~ | ~ X_1, X_0)$ 원래는 이런 식... 이전의 모든 차수가 영향을 줌\n",
    "* $P(X_t ~ | ~ X_{t-1}, \\cdots, X_0) = P(X_t ~ | ~ X_{t-1})$로 축약.\n",
    "> 어느 시점에 있던지, transition되는 확률은 동일하다. $p(X_t = s ~ | ~ X_{t-1} = t) = p(X_{t+1} = s ~ | ~ X_t = t)$\n",
    ">\n",
    "> 직전 시점에서의 영향력만 있는 게 아니라, 과거 시점에서의 영향력도 체인이기 때문에 존재한다.\n",
    "\n",
    "* $p_{st}$ 현재 상태가 $t$일 때, 다음이 $s$일 확률. $p(X_{t+1} = s ~ | ~ X_t = t)$\n",
    "\n",
    "$$\\mathbf{P} = \\begin{bmatrix} p_{11} & \\cdots & p_{1k} \\end{bmatrix}$$\n",
    "\n",
    "> 행으로 더하면, 1이 나옴. 다 더하면 k가 나옴."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "564cd70e",
   "metadata": {},
   "source": [
    "`-` Notations\n",
    "\n",
    "$$\\begin{align}\n",
    "P_i(X_n = k) & \\overset{\\text{def}}{=} P(X_n = v_k ~ | ~ X_0 = v_i) \\\\\n",
    "T_i^{(r+1)} & \\overset{\\text{def}}{=} \\inf \\{n ≥ T_i^{(r)} + 1 ~ | ~ X_n = v_i\\}\n",
    "\\end{align}$$\n",
    "\n",
    "* 초기값 $v_i$에서 출발했을 때, 다시 $v_i$로 돌아오기까지의 최소 시간\n",
    "> 해당 값이 다시 관측되기까지의 빈도 계산이 가능. $n \\to \\infty$일 때, 관측된 돌아오는 빈도는 $\\infty$여야 함.\n",
    "* 다시 초기값이 나타나지 않는 경우, stationary하지 않음."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "949cc22b",
   "metadata": {},
   "source": [
    "`-` Specific version Markov chain을 고려\n",
    "\n",
    "1. Irreducibility: Connectiveness. communication\n",
    "> 모든 상태들은 서로 연결되어 있어서 다른 상태로 돌아갈 확률이 존재해야 함. 언젠가는 연결되어야 한다. 쌍방향으로 연결되어 있어야 함.\n",
    "\n",
    "2. Recurrency\n",
    "> 언젠가 다시 돌아올 확률은 1이다. 모든 값들에 대한 확률을 합하면 무한\n",
    "\n",
    "3. Aperiodicity\n",
    "> 주기성이 없어야 한다. multiple hidden distributions을 만들고 싶지 않다. 한 개의 hidden distribution만 존재해야 함.\n",
    "\n",
    "위 세 가지를 만족하면, stationary distribution을 얻을 수 있다.\n",
    "\n",
    "\n",
    "* state가 유한인 상황에서 Irreducibility만 존재한다면, Recurrency도 만족함. 세 가지 조건은 어느정도 유기적으로 연결되어 있지만... 그정도 까지는..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30ae8695",
   "metadata": {},
   "source": [
    "`-` Stationary distribution\n",
    "\n",
    "$\\lambda^{\\top}P^n \\to \\lambda^{\\top}\\tilde{P} = \\pi^{\\top}$\n",
    "\n",
    "* 중요함 $\\pi^{\\top} = \\pi^{\\top}P$. transition을 해도 똑같은 분포가 나옴.\n",
    "* 초기의 분포 $\\lambda$가 어떤지는 전혀 영향을 주지 않음. $P$에 의해서만 영향을 받는다.\n",
    "* Chain이 늘어갈 수록, 초기값을 잊어버림. Long memory 소실. 한참 지나가야 stationary하게 바뀐다고 말할 수 있음. Markov chain 앞쪽 샘플을 사용하면 성능이 떨어질 수 있음 $\\to$ 거의 절반을 제거. stationary distribution에 가까이 가있는 샘플들만 사용. **burn-in**\n",
    "\n",
    "`example`\n",
    "\n",
    "$$(0.5, 0.1, 0.4) \\begin{bmatrix} 0.1 & 0.9 & 0.0 \\\\\n",
    "0.2 & 0.7 & 0.1 \\\\\n",
    "0.3 & 0.2 & 0.5\n",
    " \\end{bmatrix}$$\n",
    "\n",
    "초기 상태의 확률 $\\lambda = (0.5, 0.1, 0.4)$가 존재할 때, Transition probatility를 곱하면, 다음 상태의 확률 $\\pi^{\\top}$이 나옴\n",
    "\n",
    "> 그 다음 확률은 $P^2$으로 구할 수 있음.\n",
    ">\n",
    "> 초기값을 어떻게 잡아도, $P^n$이 수렴하면서 각 케이스가 나올 확률이 수렴하게 됨. 그 확률 $\\pi$를 구하기 위한 것임."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ae9f290",
   "metadata": {},
   "source": [
    "`-` Ergodicity of Markov chain\n",
    "\n",
    "$$\\sum_{i=1}^n f(X_n) / n \\to E_{\\pi}[f(X)] ~ \\text{a.e.}$$\n",
    "\n",
    "as $n \\to \\infty$ where $f$ is a mesurable function.\n",
    "\n",
    "> Markov chain에서의 LLN\n",
    ">\n",
    "> 하지만 i.i.d. sample에서의 표본평균 분산보다 더 높음. 수렴의 속도가 i.i.d.보다 떨어짐."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ef1e5d3",
   "metadata": {},
   "source": [
    "## 6. MH algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c213e9d",
   "metadata": {},
   "source": [
    "kernel의 원래 정의는 핵심 요소라는 뜻임. 그냥 여러 곳에서 다 씀 ㅇㅇ."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10fda013",
   "metadata": {},
   "source": [
    "모든, 왠만한 문제에 다 사용 가능한 알고리즘. 깁 샘플링은 중요하지만 뺐음...\n",
    "\n",
    "* Continuous Markov chain을 고려: Kernel을 사용\n",
    "\n",
    "$$\\mathbb P (X_{t+1} \\in \\mathcal B ~ | ~ X_t = x, X_{t-1}= \\cdots) = \\int_{\\mathcal B}k(x, y)dy$$\n",
    "\n",
    "> $k$는 다음 상태에 대한 확률을 결정해주는 density. x에서 y로 갈 확률\n",
    ">\n",
    "> 가장 일반적인 형태: 평균을 사용. $X_t = x, ~ X_{t+1} = y \\sim N(x, \\sigma^2)$\n",
    "\n",
    "* By the stationary condition\n",
    "\n",
    "$$\\int k(x, y)\\pi(x)dx = \\pi(y), ~ $$\n",
    "\n",
    "> stationary distribution $\\pi$을 가진다면, 이것을 어떤 방식으로 확인할 수 있는지를 알려줌.\n",
    ">\n",
    "> $\\pi$를 지정하고, $k(x, y)\\pi(x) = k(y, x)\\pi(y)$를 만족하는 $k$를 어떻게든 만들자는 것이 MH 알고리즘."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66cff8b3",
   "metadata": {},
   "source": [
    "`-` MH 알고리즘\n",
    "\n",
    "1. $k(x, y)\\pi(x) = k(y, x)\\pi(y)$를 만족하는 $k$를 만듦\n",
    "2. $k(x, x) = \\alpha > 0$을 지정하여 recurrency 확보"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05db6bcc",
   "metadata": {},
   "source": [
    "3. Calculation of\n",
    "\n",
    "$$\\alpha_{xy} = \\min \\left{1, \\frac{\\pi(y)k(y,x)}{\\pi(x)k(x,y)} \\right}$$\n",
    "\n",
    "4. $U ≤ \\alpha_{xy}$, let\n",
    "> 자기자신을 그대로 유지하고자 하는 확률이 존재하기 때문에 같은 값으로 샘플링되는 경우가 생김.\n",
    "\n",
    "> 가능하면 $\\alpha_{xy}$가 높기를 바람. 너무 낮으면 계속 같아지니까...\n",
    ">\n",
    "> $\\pi(y) > \\pi(x)$이면 무조건 변화. 아니면 변화 안할 수 있음."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e16adaa7",
   "metadata": {},
   "source": [
    "* 정규분포 하에서는 $x \\to y$ kernel이나, $y \\to x$ kernel이나 똑같음을 간단하게 유도해낼 수 있음. 이 경우 $k$를 캔슬할 수 있기 때문에 이전 값을 평균으로 사용하는 커널을 잘 사용한다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1302f95d",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
